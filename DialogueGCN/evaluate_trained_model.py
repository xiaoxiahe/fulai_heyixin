#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹è¿›è¡Œè¯„ä¼°
å‚è€ƒfinal_emotion_system.pyçš„é€»è¾‘
"""
import sys
import os
import torch
import torch.nn as nn
import numpy as np
import time
import pandas as pd
from collections import Counter
from typing import Dict, Any, List, Optional, Tuple

# å¯¼å…¥BERTç›¸å…³åº“
try:
    from transformers import AutoTokenizer, AutoModel
    BERT_AVAILABLE = True
except ImportError:
    BERT_AVAILABLE = False
    print("âš ï¸ BERTåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰¹å¾æå–")

# å¯¼å…¥æ¨¡å‹
try:
    from model import DialogueGCNModel
    MODEL_AVAILABLE = True
except ImportError:
    MODEL_AVAILABLE = False
    print("âŒ æ— æ³•å¯¼å…¥DialogueGCNæ¨¡å‹")

class DialogueGCNEvaluator:
    """DialogueGCNæ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, model_path, device='auto', confidence_threshold=None, per_emotion_thresholds=None):
        """åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.pklæ–‡ä»¶ï¼‰
            device: è®¾å¤‡ ('cuda', 'cpu', æˆ– 'auto')
            confidence_threshold: å…¨å±€ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œéneutralæƒ…ç»ªéœ€è¶…è¿‡æ­¤é˜ˆå€¼æ‰è¢«æ¥å—
            per_emotion_thresholds: æ¯ç±»æƒ…ç»ªçš„ä¸ªæ€§åŒ–é˜ˆå€¼å­—å…¸ï¼Œæ ¼å¼ï¼š{'HAPPY': 0.35, 'SAD': 0.40, 'ANGRY': 0.27}
        """
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if device == 'auto':
            if torch.cuda.is_available():
                self.device = 'cuda'
                print("ğŸš€ æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
            else:
                self.device = 'cpu'
                print("ğŸ’» ä½¿ç”¨CPUè¿è¡Œ")
        else:
            self.device = device
        
        # æƒ…ç»ªæ ‡ç­¾æ˜ å°„ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ - train_chinese_auto_dim.pyä¸­n_classes=4ï¼‰
        self.emotion_map = {
            0: 'NEUTRAL',
            1: 'HAPPY',
            2: 'SAD',
            3: 'ANGRY'
        }
        
        self.reverse_emotion_map = {v: k for k, v in self.emotion_map.items()}
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        # ç½®ä¿¡åº¦é˜ˆå€¼
        self.confidence_threshold = confidence_threshold
        self.per_emotion_thresholds = per_emotion_thresholds or {}
        
        if confidence_threshold is not None:
            print(f"ğŸšï¸ å…¨å±€ç½®ä¿¡åº¦é˜ˆå€¼å·²è®¾ç½®: {confidence_threshold:.1%} (éneutralæƒ…ç»ªéœ€è¶…è¿‡æ­¤é˜ˆå€¼)")
        
        if per_emotion_thresholds:
            print("ğŸšï¸ ä¸ªæ€§åŒ–æƒ…ç»ªé˜ˆå€¼å·²è®¾ç½®:")
            for emotion, threshold in per_emotion_thresholds.items():
                print(f"   {emotion}: {threshold:.1%}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.tokenizer = None
        self.bert_model = None
        
        # åŠ è½½æ¨¡å‹å’ŒBERT
        self.load_model(model_path)
        self.load_bert()
    
    def reset_dialogue_context(self):
        """é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡"""
        self.conversation_history = []
        print("ğŸ”„ å¯¹è¯ä¸Šä¸‹æ–‡å·²é‡ç½®")
    
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹"""
        print(f"æ­£åœ¨åŠ è½½DialogueGCNæ¨¡å‹: {model_path}")
        
        if not MODEL_AVAILABLE:
            print("âŒ æ— æ³•å¯¼å…¥DialogueGCNæ¨¡å‹ï¼Œè¯·ç¡®ä¿model.pyå­˜åœ¨")
            return False
        
        try:
            # åŠ è½½æ£€æŸ¥ç‚¹
            if not os.path.exists(model_path):
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False
            
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            # è·å–æ¨¡å‹å‚æ•°
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                print("âœ… æ£€æµ‹åˆ°æ ‡å‡†æ£€æŸ¥ç‚¹æ ¼å¼")
                model_state = checkpoint['model_state_dict']
                
                # æ‰“å°æ£€æŸ¥ç‚¹ä¿¡æ¯
                if 'epoch' in checkpoint:
                    print(f"   è®­ç»ƒEpoch: {checkpoint['epoch'] + 1}")
                if 'test_fscore' in checkpoint:
                    print(f"   æµ‹è¯•F1: {checkpoint['test_fscore']:.2f}%")
                if 'test_acc' in checkpoint:
                    print(f"   æµ‹è¯•å‡†ç¡®ç‡: {checkpoint['test_acc']:.2f}%")
                if 'feature_dim' in checkpoint:
                    feature_dim = checkpoint['feature_dim']
                    print(f"   ç‰¹å¾ç»´åº¦: {feature_dim}")
                else:
                    feature_dim = 768  # é»˜è®¤å€¼
                
                # ä¿å­˜ç‰¹å¾ç»´åº¦åˆ°å®ä¾‹å±æ€§
                self.feature_dim = feature_dim
                
                # è·å–è®­ç»ƒå‚æ•°å’Œæ¨¡å‹é…ç½®
                args = checkpoint.get('args', None)
                config = checkpoint.get('config', {})
                
                # ä»æ£€æŸ¥ç‚¹æˆ–é…ç½®ä¸­è¯»å–æ¨¡å‹ç»´åº¦å‚æ•°
                # ä¼˜å…ˆä½¿ç”¨configï¼Œå…¶æ¬¡ä½¿ç”¨checkpointä¸­ç›´æ¥ä¿å­˜çš„å€¼ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
                D_m = feature_dim
                
                # ä»æ¨¡å‹æƒé‡æ¨æ–­ç»´åº¦ï¼ˆæ›´å‡†ç¡®ï¼‰
                # æ³¨æ„ï¼šåœ¨DialogueGCNModelä¸­ï¼ŒLSTM/GRUä½¿ç”¨çš„æ˜¯ hidden_size=D_eï¼ˆä¸æ˜¯D_hï¼‰
                try:
                    # ä»LSTM/GRUæƒé‡æ¨æ–­D_e
                    if 'lstm.weight_ih_l0' in model_state:
                        lstm_weight_shape = model_state['lstm.weight_ih_l0'].shape
                        D_e = lstm_weight_shape[0] // 4  # LSTMæœ‰4ä¸ªé—¨
                        print(f"   ä»LSTMæƒé‡æ¨æ–­D_e: {D_e}")
                    elif 'gru.weight_ih_l0' in model_state:
                        gru_weight_shape = model_state['gru.weight_ih_l0'].shape
                        D_e = gru_weight_shape[0] // 3  # GRUæœ‰3ä¸ªé—¨
                        print(f"   ä»GRUæƒé‡æ¨æ–­D_e: {D_e}")
                    else:
                        D_e = config.get('D_e', 150 if D_m > 1000 else 100)
                        print(f"   ä½¿ç”¨é…ç½®æˆ–é»˜è®¤D_e: {D_e}")
                    
                    # ä»å›¾ç½‘ç»œæƒé‡æ¨æ–­graph_h
                    if 'graph_net.conv1.bias' in model_state:
                        graph_h = model_state['graph_net.conv1.bias'].shape[0]
                        print(f"   ä»å›¾ç½‘ç»œæƒé‡æ¨æ–­graph_h: {graph_h}")
                    else:
                        graph_h = config.get('graph_h', 150 if D_m > 1000 else 100)
                        print(f"   ä½¿ç”¨é…ç½®æˆ–é»˜è®¤graph_h: {graph_h}")
                    
                    # å…¶ä»–ç»´åº¦
                    D_g = config.get('D_g', graph_h)
                    D_p = config.get('D_p', D_g)
                    D_h = config.get('D_h', D_e)  # D_hé€šå¸¸ç­‰äºD_e
                    D_a = config.get('D_a', 100)
                    
                except Exception as e:
                    print(f"   âš ï¸ ä»æƒé‡æ¨æ–­ç»´åº¦å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
                    # æ ¹æ®ç‰¹å¾ç»´åº¦æ¨æ–­å…¶ä»–ç»´åº¦ï¼ˆå›é€€æ–¹æ¡ˆï¼‰
                    if D_m > 1000:
                        D_g = config.get('D_g', 200)
                        D_p = config.get('D_p', 200)
                        D_e = config.get('D_e', 150)
                        D_h = config.get('D_h', 150)
                        D_a = config.get('D_a', 100)
                        graph_h = config.get('graph_h', 150)
                    else:
                        D_g = config.get('D_g', 150)
                        D_p = config.get('D_p', 150)
                        D_e = config.get('D_e', 100)
                        D_h = config.get('D_h', 100)
                        D_a = config.get('D_a', 100)
                        graph_h = config.get('graph_h', 100)
                
                print(f"   æ¨¡å‹é…ç½®: D_e={D_e}, D_h={D_h}, D_g={D_g}, graph_h={graph_h}")
                
                # ä»æ¨¡å‹æƒé‡æ¨æ–­base_modelç±»å‹
                if 'lstm.weight_ih_l0' in model_state:
                    base_model = 'LSTM'
                elif 'gru.weight_ih_l0' in model_state:
                    base_model = 'GRU'
                elif 'dialog_rnn_f.g_cell.weight_ih' in model_state:
                    base_model = 'DialogRNN'
                else:
                    base_model = 'LSTM'  # é»˜è®¤
                print(f"   æ£€æµ‹åˆ°base_model: {base_model}")
                
                # ä»checkpointä¸­è¯»å–è®­ç»ƒæ—¶çš„çª—å£å‚æ•°
                window_past = 10  # é»˜è®¤å€¼
                window_future = 10  # é»˜è®¤å€¼
                listener_state = False
                context_attention = 'simple'
                dropout_rec = 0.1
                dropout = 0.5
                nodal_attention = False
                avec = False
                
                # å°è¯•ä»argsä¸­è¯»å–è®­ç»ƒæ—¶çš„å‚æ•°
                if args:
                    window_past = getattr(args, 'windowp', 10)
                    window_future = getattr(args, 'windowf', 10)
                    listener_state = getattr(args, 'active_listener', False)
                    context_attention = getattr(args, 'attention', 'simple')
                    dropout_rec = getattr(args, 'rec_dropout', 0.1)
                    dropout = getattr(args, 'dropout', 0.5)
                    nodal_attention = getattr(args, 'nodal_attention', False)
                    avec = getattr(args, 'avec', False)
                
                print(f"   è®­ç»ƒå‚æ•°: base_model={base_model}, window_past={window_past}, window_future={window_future}")
                print(f"   æ³¨æ„åŠ›å‚æ•°: listener_state={listener_state}, context_attention={context_attention}, nodal_attention={nodal_attention}")
                print(f"   Dropoutå‚æ•°: dropout={dropout}, dropout_rec={dropout_rec}")
                
                # ä¿å­˜çª—å£å‚æ•°ä¾›é¢„æµ‹æ—¶ä½¿ç”¨
                self.window_past = window_past
                self.window_future = window_future
                
                # ä»checkpointä¸­è¯»å–ç‰¹å¾æå–é…ç½®
                self.use_context_window = getattr(args, 'use_context_window', False)
                self.context_window_size = getattr(args, 'context_window_size', 8)
                self.pooling_strategy = getattr(args, 'pooling_strategy', 'auto')
                
                print(f"   ç‰¹å¾æå–é…ç½®: use_context_window={self.use_context_window}, context_window_size={self.context_window_size}")
                print(f"   æ± åŒ–ç­–ç•¥: {self.pooling_strategy}")
                
                # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                self.model = DialogueGCNModel(
                    base_model=base_model,
                    D_m=D_m,
                    D_g=D_g,
                    D_p=D_p,
                    D_e=D_e,
                    D_h=D_h,
                    D_a=D_a,
                    graph_hidden_size=graph_h,
                    n_speakers=4,
                    max_seq_len=300,
                    window_past=window_past,
                    window_future=window_future,
                    n_classes=4,
                    listener_state=listener_state,
                    context_attention=context_attention,
                    dropout_rec=dropout_rec,
                    dropout=dropout,
                    nodal_attention=nodal_attention,
                    avec=avec,
                    no_cuda=(self.device == 'cpu')
                )
                
                # åŠ è½½æƒé‡
                self.model.load_state_dict(model_state)
                print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡")
                
            else:
                print("âŒ ä¸æ”¯æŒçš„æ£€æŸ¥ç‚¹æ ¼å¼")
                return False
            
            self.model.to(self.device)
            self.model.eval()
            print(f"âœ… æ¨¡å‹å·²è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def load_bert(self):
        """åŠ è½½BERTæ¨¡å‹"""
        if not BERT_AVAILABLE:
            print("âš ï¸ transformersåº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰¹å¾æå–")
            return False
        
        print("æ­£åœ¨åŠ è½½chinese-roberta-wwm-extæ¨¡å‹...")
        try:
            cache_dir = "./bert_cache"
            os.makedirs(cache_dir, exist_ok=True)
            model_name = 'hfl/chinese-roberta-wwm-ext'
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert_model = AutoModel.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert_model.to(self.device)
            self.bert_model.eval()
            print("âœ… BERTæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def extract_bert_features(self, text, pooling_strategy='auto'):
        """
        æå–BERTç‰¹å¾ - æ”¯æŒgpu_processor_enhanced.pyçš„å¤šç§æ± åŒ–ç­–ç•¥
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            pooling_strategy: æ± åŒ–ç­–ç•¥ ('auto', 'cls', 'mean', 'max', 'multi')
        """
        if self.bert_model is None or self.tokenizer is None:
            # å¦‚æœBERTä¸å¯ç”¨ï¼Œè¿”å›é›¶å‘é‡
            return torch.zeros(self.feature_dim, device=self.device)
        
        try:
            text = text.strip()
            if not text:
                return torch.zeros(self.feature_dim, device=self.device)
            
            # æ ¹æ®ç‰¹å¾ç»´åº¦è‡ªåŠ¨é€‰æ‹©max_length
            if self.feature_dim == 768:
                max_length = 128  # ä¸preprocess_chinese_data.pyä¸€è‡´
            elif self.feature_dim == 2304:
                max_length = 256  # ä¸gpu_processor_enhanced.pyä¸€è‡´
            else:
                max_length = 128  # é»˜è®¤å€¼
            
            inputs = self.tokenizer(
                text,
                return_tensors='pt',
                padding=True,
                truncation=True,
                max_length=max_length,
                add_special_tokens=True
            )
            
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.bert_model(**inputs)
                hidden_states = outputs.last_hidden_state  # [batch_size, seq_len, 768]
                attention_mask = inputs['attention_mask']  # [batch_size, seq_len]
                
                # æ ¹æ®ç‰¹å¾ç»´åº¦å’Œæ± åŒ–ç­–ç•¥é€‰æ‹©æå–æ–¹å¼
                if self.feature_dim == 768:
                    # å•ä¸€æ± åŒ–ï¼šåªä½¿ç”¨[CLS]æ ‡è®°ï¼ˆä¸preprocess_chinese_data.pyä¸€è‡´ï¼‰
                    features = hidden_states[:, 0, :].squeeze(0)  # [768]
                elif self.feature_dim == 2304:
                    # å¤šæ± åŒ–ç»„åˆï¼šCLS + Mean + Maxï¼ˆä¸gpu_processor_enhanced.pyä¸€è‡´ï¼‰
                    features = self._multi_pooling(hidden_states, attention_mask).squeeze(0)
                else:
                    # é»˜è®¤ä½¿ç”¨CLS
                    features = hidden_states[:, 0, :].squeeze(0)
                
                return features
                
        except Exception as e:
            print(f"âš ï¸ BERTç‰¹å¾æå–å¤±è´¥: {e}")
            return torch.zeros(self.feature_dim, device=self.device)
    
    def _cls_pooling(self, hidden_states, attention_mask):
        """[CLS] token pooling"""
        return hidden_states[:, 0, :]
    
    def _mean_pooling(self, hidden_states, attention_mask):
        """å‡å€¼æ± åŒ–"""
        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()
        sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)
        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)
        return sum_embeddings / sum_mask
    
    def _max_pooling(self, hidden_states, attention_mask):
        """æœ€å¤§æ± åŒ–"""
        input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()
        hidden_states_clone = hidden_states.clone()
        hidden_states_clone[input_mask_expanded == 0] = -1e9
        return torch.max(hidden_states_clone, 1)[0]
    
    def _multi_pooling(self, hidden_states, attention_mask):
        """å¤šç§æ± åŒ–ç­–ç•¥ç»„åˆï¼ˆä¸gpu_processor_enhanced.pyä¸€è‡´ï¼‰"""
        cls_pooled = self._cls_pooling(hidden_states, attention_mask)
        mean_pooled = self._mean_pooling(hidden_states, attention_mask)
        max_pooled = self._max_pooling(hidden_states, attention_mask)
        return torch.cat([cls_pooled, mean_pooled, max_pooled], dim=-1)
    
    def extract_contextual_features(self, texts, speakers, window_size=8):
        """
        æå–å¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç‰¹å¾ï¼ˆå‚è€ƒgpu_processor_enhanced.pyï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            speakers: è¯´è¯è€…åˆ—è¡¨
            window_size: ä¸Šä¸‹æ–‡çª—å£å¤§å°
        
        Returns:
            å¢å¼ºåçš„ç‰¹å¾åˆ—è¡¨
        """
        if len(texts) == 0:
            return []
        
        enhanced_features = []
        
        for idx in range(len(texts)):
            # è·å–ä¸Šä¸‹æ–‡çª—å£
            start_idx = max(0, idx - window_size)
            end_idx = min(len(texts), idx + window_size + 1)
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context_texts = []
            for i in range(start_idx, end_idx):
                speaker = speakers[i] if i < len(speakers) else "?"
                text = texts[i]
                context_texts.append(f"{speaker}: {text}")
            
            context_str = " [SEP] ".join(context_texts)
            
            # æå–å½“å‰ç‰¹å¾
            current_features = self.extract_bert_features(texts[idx])
            
            # æå–ä¸Šä¸‹æ–‡ç‰¹å¾
            context_features = self.extract_bert_features(context_str)
            
            # ç»„åˆï¼šå½“å‰70% + ä¸Šä¸‹æ–‡30%ï¼ˆä¸gpu_processor_enhanced.pyä¸€è‡´ï¼‰
            combined = 0.7 * current_features + 0.3 * context_features
            enhanced_features.append(combined)
        
        return enhanced_features
    
    def predict_emotion(self, user_text, robot_text=""):
        """é¢„æµ‹æƒ…ç»ª
        
        Args:
            user_text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            robot_text: æœºå™¨äººå›å¤æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            DictåŒ…å«emotion, confidence, probabilities
        """
        if self.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None
        
        try:
            self.model.to(self.device)
            self.model.eval()
            
            # æ„å»ºå¯¹è¯åºåˆ—
            conversation = []
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶çš„çª—å£å‚æ•°ï¼‰
            # ä»checkpointä¸­è·å–window_pastå’Œwindow_futureå‚æ•°
            window_past = getattr(self, 'window_past', 10)  # é»˜è®¤å€¼
            window_future = getattr(self, 'window_future', 10)  # é»˜è®¤å€¼
            
            # æ ¹æ®çª—å£å‚æ•°æ·»åŠ å†å²å¯¹è¯
            history_length = min(len(self.conversation_history), window_past)
            for hist_text, hist_speaker in self.conversation_history[-history_length:]:
                conversation.append((hist_text, hist_speaker))
            
            # æ·»åŠ å½“å‰å¯¹è¯
            if robot_text:
                conversation.append((robot_text, 1))  # robot
            conversation.append((user_text, 0))  # user
            
            # é™åˆ¶å¯¹è¯é•¿åº¦ä»¥é¿å…ç»´åº¦é—®é¢˜
            # å¦‚æœå¯¹è¯å¤ªé•¿ï¼Œåªä¿ç•™æœ€è¿‘çš„å‡ è½®
            max_conversation_length = 10  # é™åˆ¶æœ€å¤§å¯¹è¯é•¿åº¦
            if len(conversation) > max_conversation_length:
                conversation = conversation[-max_conversation_length:]
            
            # æå–ç‰¹å¾ - æ”¯æŒä¸Šä¸‹æ–‡çª—å£å¢å¼º
            text_features = []
            speaker_features = []
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸Šä¸‹æ–‡çª—å£ç‰¹å¾æå–
            use_context_window = getattr(self, 'use_context_window', False)
            context_window_size = getattr(self, 'context_window_size', 8)
            
            if use_context_window and len(conversation) > 1:
                # ä½¿ç”¨ä¸Šä¸‹æ–‡çª—å£ç‰¹å¾æå–ï¼ˆå‚è€ƒgpu_processor_enhanced.pyï¼‰
                texts = [text for text, _ in conversation]
                speakers = [speaker for _, speaker in conversation]
                enhanced_features = self.extract_contextual_features(texts, speakers, context_window_size)
                
                for i, (text, speaker) in enumerate(conversation):
                    if i < len(enhanced_features):
                        text_feature = enhanced_features[i]
                    else:
                        text_feature = self.extract_bert_features(text)
                    
                    if text_feature.is_cuda:
                        text_feature = text_feature.cpu()
                    text_features.append(text_feature.numpy())
                    
                    # One-hotç¼–ç è¯´è¯è€…
                    speaker_feature = [0.0] * 4  # 4ä¸ªè¯´è¯è€…
                    speaker_feature[speaker] = 1.0
                    speaker_features.append(speaker_feature)
            else:
                # æ ‡å‡†ç‰¹å¾æå–
                for text, speaker in conversation:
                    text_feature = self.extract_bert_features(text)
                    if text_feature.is_cuda:
                        text_feature = text_feature.cpu()
                    text_features.append(text_feature.numpy())
                    
                    # One-hotç¼–ç è¯´è¯è€…
                    speaker_feature = [0.0] * 4  # 4ä¸ªè¯´è¯è€…
                    speaker_feature[speaker] = 1.0
                    speaker_features.append(speaker_feature)
            
            # è½¬æ¢ä¸ºå¼ é‡
            # æ³¨æ„ï¼šDialogueGCNæœŸæœ›çš„è¾“å…¥æ ¼å¼æ˜¯ (seq_len, batch_size, feature_dim)
            # å¯¹äºå•ä¸ªå¯¹è¯çš„é¢„æµ‹ï¼Œbatch_size=1
            text_features = torch.FloatTensor(np.array(text_features)).unsqueeze(1).to(self.device)  # (seq_len, 1, feature_dim)
            speaker_features = torch.FloatTensor(np.array(speaker_features)).unsqueeze(1).to(self.device)  # (seq_len, 1, n_speakers)
            
            # åˆ›å»ºmask
            seq_len = text_features.shape[0]  # ç¬¬0ç»´æ˜¯seq_len
            batch_size = 1  # å•ä¸ªå¯¹è¯é¢„æµ‹
            
            # ç¡®ä¿maskçš„å½¢çŠ¶æ­£ç¡®
            # MatchingAttentionæœŸæœ›maskçš„å½¢çŠ¶æ˜¯(batch_size, seq_len)
            umask = torch.ones(batch_size, seq_len).to(self.device)  # (batch_size, seq_len)
            qmask = speaker_features  # (seq_len, batch_size, n_speakers)
            
            # åºåˆ—é•¿åº¦
            lengths = [seq_len]
            
            # é¢„æµ‹
            with torch.no_grad():
                # è°ƒç”¨æ¨¡å‹
                log_prob, _, _, _, _ = self.model(text_features, qmask, umask, lengths)
                
                # log_probçš„å½¢çŠ¶åº”è¯¥æ˜¯ (total_utterances, n_classes)
                # è·å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„é¢„æµ‹
                if log_prob.dim() == 2:
                    last_logits = log_prob[-1]  # æœ€åä¸€æ¡utterance
                else:
                    last_logits = log_prob[-1, :]
                
                probabilities = torch.exp(last_logits)
                predicted_class = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_class].item()
            
            # æ„å»ºæ¦‚ç‡å­—å…¸
            probs = {}
            for i, emotion in self.emotion_map.items():
                probs[emotion] = probabilities[i].item()
            
            # åº”ç”¨ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤
            final_emotion = self.emotion_map[predicted_class]
            final_confidence = confidence
            threshold_applied = False
            threshold_type = None
            
            # å¯¹ä»»ä½•éNEUTRALæƒ…ç»ªéƒ½è¿›è¡Œé˜ˆå€¼æ£€æŸ¥
            if final_emotion != 'NEUTRAL':
                threshold_to_use = None
                
                # ä¼˜å…ˆä½¿ç”¨ä¸ªæ€§åŒ–é˜ˆå€¼
                if final_emotion in self.per_emotion_thresholds:
                    threshold_to_use = self.per_emotion_thresholds[final_emotion]
                    threshold_type = f"ä¸ªæ€§åŒ–({final_emotion})"
                # å…¶æ¬¡ä½¿ç”¨å…¨å±€é˜ˆå€¼
                elif self.confidence_threshold is not None:
                    threshold_to_use = self.confidence_threshold
                    threshold_type = "å…¨å±€"
                
                # å¦‚æœè®¾ç½®äº†é˜ˆå€¼ä¸”ç½®ä¿¡åº¦æœªè¾¾åˆ°ï¼Œå¼ºåˆ¶æ”¹ä¸ºNEUTRAL
                if threshold_to_use is not None and confidence < threshold_to_use:
                    final_emotion = 'NEUTRAL'
                    final_confidence = probs['NEUTRAL']
                    threshold_applied = True
            
            # æ›´æ–°å¯¹è¯å†å²
            if robot_text:
                self.conversation_history.append((robot_text, 1))
            self.conversation_history.append((user_text, 0))
            
            # ä¿æŒå†å²é•¿åº¦
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            result = {
                'emotion': final_emotion,
                'confidence': final_confidence,
                'probabilities': probs,
                'source': 'dialoguegcn'
            }
            
            # å¦‚æœåº”ç”¨äº†é˜ˆå€¼è¿‡æ»¤ï¼Œæ·»åŠ ç›¸å…³ä¿¡æ¯
            if threshold_applied:
                result['original_emotion'] = self.emotion_map[predicted_class]
                result['original_confidence'] = confidence
                result['threshold_applied'] = True
                result['threshold_type'] = threshold_type
            
            return result
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_interactive(self):
        """äº¤äº’å¼è¯„ä¼°æ¨¡å¼"""
        print("\n" + "="*60)
        print("ğŸ¯ DialogueGCNäº¤äº’å¼è¯„ä¼°")
        print("="*60)
        print("ä½¿ç”¨è®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹è¿›è¡Œæƒ…ç»ªé¢„æµ‹")
        print("æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡")
        print("è¾“å…¥ 'quit' é€€å‡º")
        print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
        print("è¾“å…¥ 'stats' æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
        print("="*60)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_predictions = 0
        prediction_times = []
        emotion_counts = Counter()
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
                
                if user_input.lower() == 'quit':
                    if total_predictions > 0:
                        print("\n" + "="*60)
                        print("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
                        print("="*60)
                        print(f"æ€»é¢„æµ‹æ¬¡æ•°: {total_predictions}")
                        print(f"å¹³å‡è€—æ—¶: {np.mean(prediction_times):.2f}ms")
                        if len(prediction_times) > 1:
                            print(f"è€—æ—¶èŒƒå›´: {np.min(prediction_times):.2f}ms - {np.max(prediction_times):.2f}ms")
                        print(f"\næƒ…ç»ªåˆ†å¸ƒ:")
                        for emotion, count in emotion_counts.most_common():
                            print(f"  {emotion}: {count} ({count/total_predictions*100:.1f}%)")
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
                    
                elif user_input.lower() == 'clear':
                    self.reset_dialogue_context()
                    continue
                    
                elif user_input.lower() == 'history':
                    print("\nğŸ“œ å¯¹è¯å†å²:")
                    if not self.conversation_history:
                        print("   æš‚æ— å¯¹è¯å†å²")
                    else:
                        for i, (text, speaker) in enumerate(self.conversation_history[-10:]):
                            speaker_name = "ç”¨æˆ·" if speaker == 0 else "æœºå™¨äºº"
                            print(f"   {i+1}. {speaker_name}: {text}")
                    continue
                    
                elif user_input.lower() == 'stats':
                    print("\nğŸ“Š å½“å‰ç»Ÿè®¡:")
                    print(f"æ€»é¢„æµ‹æ¬¡æ•°: {total_predictions}")
                    if prediction_times:
                        print(f"å¹³å‡è€—æ—¶: {np.mean(prediction_times):.2f}ms")
                    print(f"å¯¹è¯å†å²é•¿åº¦: {len(self.conversation_history)}")
                    if emotion_counts:
                        print(f"æƒ…ç»ªåˆ†å¸ƒ:")
                        for emotion, count in emotion_counts.most_common():
                            print(f"  {emotion}: {count} ({count/total_predictions*100:.1f}%)")
                    continue
                    
                elif not user_input:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                    continue
                
                # é¢„æµ‹æƒ…ç»ª
                print("\nğŸ” æ­£åœ¨ä½¿ç”¨DialogueGCNåˆ†ææƒ…ç»ª...")
                t0 = time.perf_counter()
                result = self.predict_emotion(user_input, robot_text="")
                elapsed_ms = (time.perf_counter() - t0) * 1000.0
                
                if result:
                    emotion = result['emotion']
                    confidence = result['confidence']
                    probabilities = result['probabilities']
                    
                    # æ›´æ–°ç»Ÿè®¡
                    total_predictions += 1
                    prediction_times.append(elapsed_ms)
                    emotion_counts[emotion] += 1
                    
                    # æ˜¾ç¤ºç»“æœ
                    print(f"\nğŸ“Š DialogueGCNé¢„æµ‹ç»“æœ:")
                    print(f"   é¢„æµ‹æƒ…ç»ª: {emotion} (ç½®ä¿¡åº¦: {confidence:.2%})")
                    
                    # å¦‚æœåº”ç”¨äº†ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼Œæ˜¾ç¤ºåŸå§‹é¢„æµ‹
                    if result.get('threshold_applied', False):
                        original_emotion = result['original_emotion']
                        original_confidence = result['original_confidence']
                        threshold_type = result.get('threshold_type', 'æœªçŸ¥')
                        print(f"   ğŸšï¸ {threshold_type}é˜ˆå€¼è¿‡æ»¤: {original_emotion} ({original_confidence:.2%}) â†’ {emotion} ({confidence:.2%})")
                    
                    print(f"   é¢„æµ‹è€—æ—¶: {elapsed_ms:.2f}ms")
                    print(f"   æ‰€æœ‰æƒ…ç»ªæ¦‚ç‡:")
                    for emo, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):
                        bar = "â–ˆ" * int(prob * 20)
                        print(f"     {emo:8}: {prob:.2%} {bar}")
                else:
                    print("âŒ é¢„æµ‹å¤±è´¥")
                    continue
                
                # å¯é€‰çš„æœºå™¨äººå›å¤
                robot_input = input("\nğŸ¤– æœºå™¨äººå›å¤ (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
                if robot_input:
                    self.conversation_history.append((robot_input, 1))
                    print(f"âœ… æœºå™¨äººå›å¤å·²è®°å½•")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
    
    def evaluate_on_file(self, data_path: str = 'improved_test_data.xlsx'):
        """ä½¿ç”¨æµ‹è¯•æ–‡ä»¶è¿›è¡Œæ‰¹é‡è¯„ä¼°ï¼ˆå®Œå…¨å‚è€ƒfinal_emotion_system.pyçš„é€»è¾‘ï¼‰
        
        Args:
            data_path: æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆ.xlsxæˆ–.csvï¼‰
            
        è¦æ±‚ï¼š
        - æ•°æ®åˆ—åŒ…å«: dialogue_id, speaker(user/robot), utterance, emotion_label
        - æœºå™¨äººè½®ä½œä¸ºå†å²å†™å…¥ï¼Œåªæœ‰æœ‰æ ‡ç­¾çš„æ‰è¿›è¡Œé¢„æµ‹
        - ç”¨æˆ·è½®ï¼šè‹¥æ— æ ‡ç­¾åˆ™ä»…ä½œä¸ºå†å²ï¼›æœ‰æ ‡ç­¾åˆ™è¿›è¡Œé¢„æµ‹æ¯”å¯¹
        - æœ€ç»ˆè¾“å‡ºï¼šæ€»ä½“å‡†ç¡®ç‡ã€å„ç±»æƒ…ç»ªå¬å›ç‡ã€å¹³å‡è€—æ—¶ã€è€—æ—¶5/50/95åˆ†ä½
        """
        try:
            from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
            _SK_AVAILABLE = True
        except Exception:
            _SK_AVAILABLE = False
            print("âš ï¸ sklearnä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–è¯„ä¼°")
        
        if not os.path.exists(data_path):
            print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {data_path}")
            return
        
        try:
            if data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
            elif data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ.xlsxæˆ–.csv")
                return
        except Exception as e:
            print(f"âŒ è¯»å–æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return
        
        required_cols = {'dialogue_id', 'speaker', 'utterance', 'emotion_label'}
        if not required_cols.issubset(set(df.columns)):
            print(f"âŒ æµ‹è¯•æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œéœ€åŒ…å«: {sorted(required_cols)}ï¼Œå½“å‰: {list(df.columns)}")
            return
        
        # æ ‡å‡†åŒ–åˆ—ç±»å‹
        df = df.copy()
        df['speaker'] = df['speaker'].astype(str)
        df['dialogue_id'] = df['dialogue_id']
        
        # ç»Ÿè®¡ä¿¡æ¯
        user_rows = df[(df['speaker'] == 'user') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        robot_rows = df[(df['speaker'] == 'robot') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        print(f"\nğŸ§ª åŸºäºæ–‡ä»¶è¿›è¡Œè¯„ä¼°...")
        print(f"æ€»è®°å½•æ•°: {len(df)} | ç”¨æˆ·(æœ‰æ ‡ç­¾)è®°å½•æ•°: {len(user_rows)} | æœºå™¨äºº(æœ‰æ ‡ç­¾)è®°å½•æ•°: {len(robot_rows)}")
        
        label_map = {
            'neutral': 'NEUTRAL',
            'happy': 'HAPPY',
            'sad': 'SAD',
            'angry': 'ANGRY'
        }
        valid_labels = ['NEUTRAL', 'HAPPY', 'SAD', 'ANGRY']
        
        y_true, y_pred, times = [], [], []
        # ç”¨äºç»Ÿè®¡æ¯ç±»æƒ…ç»ªæˆåŠŸé¢„æµ‹æ—¶çš„ç½®ä¿¡åº¦
        emotion_confidence_stats = {
            'NEUTRAL': {'success_confidences': [], 'total_predictions': 0, 'success_count': 0},
            'HAPPY': {'success_confidences': [], 'total_predictions': 0, 'success_count': 0},
            'SAD': {'success_confidences': [], 'total_predictions': 0, 'success_count': 0},
            'ANGRY': {'success_confidences': [], 'total_predictions': 0, 'success_count': 0}
        }
        
        # æŒ‰å¯¹è¯åˆ†ç»„ï¼šæ¯æ®µå¯¹è¯é‡ç½®å†…éƒ¨çŠ¶æ€ï¼Œå¤ç”¨åŒä¸€æ¨¡å‹
        for dialogue_id, group in df.groupby('dialogue_id', sort=False):
            print(f"\n=== å¯¹è¯ {dialogue_id} å¼€å§‹ï¼Œ{len(group)} æ¡ ===")
            # é‡ç½®å†…éƒ¨çŠ¶æ€ï¼Œä¿æŒæ¨¡å‹ä¸å˜
            self.reset_dialogue_context()
            
            group = group.reset_index(drop=True)
            for idx, row in group.iterrows():
                speaker = str(row['speaker']).strip().lower()
                utterance = str(row['utterance']) if not pd.isna(row['utterance']) else ''
                true_label_raw = row.get('emotion_label')
                true_label = '' if pd.isna(true_label_raw) else str(true_label_raw)
                
                if speaker == 'robot':
                    # æœºå™¨äººè½®ï¼šå…ˆæ·»åŠ åˆ°å†å²
                    if utterance.strip():
                        self.conversation_history.append((utterance.strip(), 1))
                    
                    # å¦‚æœrobotæœ‰æƒ…ç»ªæ ‡ç­¾ï¼Œä¹Ÿè¿›è¡Œé¢„æµ‹
                    if true_label.strip():
                        t0 = time.perf_counter()
                        result = self.predict_emotion(utterance, robot_text="")
                        elapsed_ms = (time.perf_counter() - t0) * 1000.0
                        
                        if result:
                            pred = result['emotion']
                            confidence = result['confidence']
                            probabilities = result['probabilities']
                        else:
                            pred = 'NEUTRAL'
                            confidence = 0.0
                            probabilities = {}
                            print(f"âš ï¸ DialogueGCNé¢„æµ‹å¤±è´¥ï¼Œé»˜è®¤ä¸ºNEUTRAL")
                        
                        mapped_true = label_map.get(true_label.lower(), true_label.upper())
                        y_true.append(mapped_true)
                        y_pred.append(pred)
                        times.append(elapsed_ms)
                        
                        # æ›´æ–°ç½®ä¿¡åº¦ç»Ÿè®¡
                        if mapped_true in emotion_confidence_stats:
                            emotion_confidence_stats[mapped_true]['total_predictions'] += 1
                            if pred == mapped_true:  # é¢„æµ‹æˆåŠŸ
                                emotion_confidence_stats[mapped_true]['success_count'] += 1
                                # åªç»Ÿè®¡é¢„æµ‹æˆåŠŸæ—¶çš„ç½®ä¿¡åº¦
                                emotion_confidence_stats[mapped_true]['success_confidences'].append(confidence)
                        
                        match_symbol = "âœ…" if pred == mapped_true else "âŒ"
                        print(f"{match_symbol} Robotè¯è¯­: {utterance}")
                        print(f"   è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} (ç½®ä¿¡åº¦: {confidence:.2%}) | å®é™…: {mapped_true}")
                        
                        # å¦‚æœåº”ç”¨äº†ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼Œæ˜¾ç¤ºåŸå§‹é¢„æµ‹
                        if result and result.get('threshold_applied', False):
                            original_emotion = result['original_emotion']
                            original_confidence = result['original_confidence']
                            threshold_type = result.get('threshold_type', 'æœªçŸ¥')
                            print(f"   ğŸšï¸ {threshold_type}é˜ˆå€¼è¿‡æ»¤: {original_emotion} ({original_confidence:.2%}) â†’ {pred} ({confidence:.2%})")
                        
                        if probabilities:
                            print(f"   å„ç±»æƒ…ç»ªç½®ä¿¡åº¦: " + " | ".join([f"{emo}: {prob:.2%}" for emo, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True)]))
                    continue
                
                if speaker == 'user':
                    # ç”¨æˆ·è½®ï¼šè‹¥æ— æ ‡ç­¾ï¼Œåˆ™ä»…ä½œä¸ºå†å²ï¼›æœ‰æ ‡ç­¾åˆ™è¿›è¡Œé¢„æµ‹æ¯”å¯¹
                    if not true_label.strip():
                        if utterance.strip():
                            self.conversation_history.append((utterance.strip(), 0))
                        continue
                    
                    # æœ‰æ ‡ç­¾ç”¨æˆ·è½®ï¼šæ‰§è¡Œé¢„æµ‹
                    t0 = time.perf_counter()
                    result = self.predict_emotion(utterance, robot_text="")
                    elapsed_ms = (time.perf_counter() - t0) * 1000.0
                    
                    if result:
                        pred = result['emotion']
                        confidence = result['confidence']
                        probabilities = result['probabilities']
                    else:
                        pred = 'NEUTRAL'
                        confidence = 0.0
                        probabilities = {}
                        print(f"âš ï¸ DialogueGCNé¢„æµ‹å¤±è´¥ï¼Œé»˜è®¤ä¸ºNEUTRAL")
                    
                    mapped_true = label_map.get(true_label.lower(), true_label.upper())
                    y_true.append(mapped_true)
                    y_pred.append(pred)
                    times.append(elapsed_ms)
                    
                    # æ›´æ–°ç½®ä¿¡åº¦ç»Ÿè®¡
                    if mapped_true in emotion_confidence_stats:
                        emotion_confidence_stats[mapped_true]['total_predictions'] += 1
                        if pred == mapped_true:  # é¢„æµ‹æˆåŠŸ
                            emotion_confidence_stats[mapped_true]['success_count'] += 1
                            # åªç»Ÿè®¡é¢„æµ‹æˆåŠŸæ—¶çš„ç½®ä¿¡åº¦
                            emotion_confidence_stats[mapped_true]['success_confidences'].append(confidence)
                    
                    match_symbol = "âœ…" if pred == mapped_true else "âŒ"
                    print(f"{match_symbol} Userè¯è¯­: {utterance}")
                    print(f"   è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} (ç½®ä¿¡åº¦: {confidence:.2%}) | å®é™…: {mapped_true}")
                    
                    # å¦‚æœåº”ç”¨äº†ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ï¼Œæ˜¾ç¤ºåŸå§‹é¢„æµ‹
                    if result and result.get('threshold_applied', False):
                        original_emotion = result['original_emotion']
                        original_confidence = result['original_confidence']
                        threshold_type = result.get('threshold_type', 'æœªçŸ¥')
                        print(f"   ğŸšï¸ {threshold_type}é˜ˆå€¼è¿‡æ»¤: {original_emotion} ({original_confidence:.2%}) â†’ {pred} ({confidence:.2%})")
                    
                    if probabilities:
                        print(f"   å„ç±»æƒ…ç»ªç½®ä¿¡åº¦: " + " | ".join([f"{emo}: {prob:.2%}" for emo, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True)]))
        
        # æ±‡æ€»æŒ‡æ ‡ï¼ˆå¢å¼ºç‰ˆ - åŒ…å«å„ç±»æƒ…ç»ªçš„è¯¦ç»†ç»Ÿè®¡ï¼‰
        if not y_true:
            print("\nâŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ ‡æ³¨æ•°æ®ï¼ˆç”¨æˆ·æˆ–æœºå™¨äººï¼‰")
            return
        
        y_true_np = np.array(y_true)
        y_pred_np = np.array(y_pred)
        accuracy = float((y_true_np == y_pred_np).mean())
        
        print("\n" + "="*80)
        print("ğŸ“Š DialogueGCNæ¨¡å‹è¯„ä¼°ç»“æœæ±‡æ€»")
        print("="*80)
        print(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"æ€»æ ·æœ¬æ•°: {len(y_true)}")
        
        # å„ç±»æƒ…ç»ªçš„è¯¦ç»†ç»Ÿè®¡
        print("\n" + "="*80)
        print("ğŸ“ˆ å„ç±»æƒ…ç»ªè¯¦ç»†ç»Ÿè®¡")
        print("="*80)
        
        if _SK_AVAILABLE:
            try:
                # è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
                precision, recall, f1, support = precision_recall_fscore_support(
                    y_true_np, y_pred_np, labels=valid_labels, zero_division=0
                )
                
                print(f"{'æƒ…ç»ªç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'æ”¯æŒæ•°':<8} {'å‡†ç¡®ç‡':<8}")
                print("-" * 70)
                
                for i, lbl in enumerate(valid_labels):
                    # è®¡ç®—è¯¥ç±»åˆ«çš„å‡†ç¡®ç‡ï¼ˆè¯¥ç±»åˆ«çš„æ­£ç¡®é¢„æµ‹æ•° / è¯¥ç±»åˆ«çš„æ€»é¢„æµ‹æ•°ï¼‰
                    class_predictions = (y_pred_np == lbl).sum()
                    class_correct = ((y_true_np == lbl) & (y_pred_np == lbl)).sum()
                    class_accuracy = class_correct / class_predictions if class_predictions > 0 else 0.0
                    
                    print(f"{lbl:<12} {precision[i]:<8.4f} {recall[i]:<8.4f} {f1[i]:<8.4f} {int(support[i]):<8} {class_accuracy:<8.4f}")
                
                # è®¡ç®—å®å¹³å‡å’Œå¾®å¹³å‡
                macro_precision = np.mean(precision)
                macro_recall = np.mean(recall)
                macro_f1 = np.mean(f1)
                
                # å¾®å¹³å‡ï¼ˆæ‰€æœ‰ç±»åˆ«çš„TPã€FPã€FNçš„æ€»å’Œï¼‰
                total_tp = sum(((y_true_np == lbl) & (y_pred_np == lbl)).sum() for lbl in valid_labels)
                total_fp = sum(((y_true_np != lbl) & (y_pred_np == lbl)).sum() for lbl in valid_labels)
                total_fn = sum(((y_true_np == lbl) & (y_pred_np != lbl)).sum() for lbl in valid_labels)
                
                micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0
                micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0
                micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0.0
                
                print("-" * 70)
                print(f"{'å®å¹³å‡':<12} {macro_precision:<8.4f} {macro_recall:<8.4f} {macro_f1:<8.4f} {'-':<8} {'-':<8}")
                print(f"{'å¾®å¹³å‡':<12} {micro_precision:<8.4f} {micro_recall:<8.4f} {micro_f1:<8.4f} {'-':<8} {'-':<8}")
                
            except Exception as e:
                print(f"  è®¡ç®—è¯¦ç»†æŒ‡æ ‡å¤±è´¥: {e}")
                # å›é€€åˆ°ç®€å•è®¡ç®—
                print("\nå„ç±»æƒ…ç»ªå¬å›ç‡:")
                for lbl in valid_labels:
                    sup = int((y_true_np == lbl).sum())
                    tp = int(((y_true_np == lbl) & (y_pred_np == lbl)).sum())
                    rec = tp / sup if sup > 0 else 0.0
                    print(f"  {lbl:<9} Recall {rec:.4f} (support={sup})")
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡ - åªç»Ÿè®¡é¢„æµ‹æˆåŠŸæ—¶çš„ç½®ä¿¡åº¦
        print("\n" + "="*80)
        print("ğŸ“Š æ¯ç±»æƒ…ç»ªé¢„æµ‹æˆåŠŸæ—¶çš„ç½®ä¿¡åº¦ç»Ÿè®¡")
        print("="*80)
        print("è¯´æ˜: é¢„æµ‹æˆåŠŸ = æ¨¡å‹é¢„æµ‹ç»“æœä¸å®é™…æ ‡ç­¾ä¸€è‡´")
        print(f"{'æƒ…ç»ªç±»åˆ«':<12} {'æˆåŠŸæ¬¡æ•°':<8} {'æˆåŠŸç‡':<8} {'æˆåŠŸæ—¶æœ€ä½ç½®ä¿¡åº¦':<16} {'æˆåŠŸæ—¶æœ€é«˜ç½®ä¿¡åº¦':<16} {'æˆåŠŸæ—¶å¹³å‡ç½®ä¿¡åº¦':<16}")
        print("-" * 90)
        
        for emotion in valid_labels:
            stats = emotion_confidence_stats[emotion]
            total_pred = stats['total_predictions']
            success_count = stats['success_count']
            success_confidences = stats['success_confidences']
            
            if total_pred > 0:
                success_rate = success_count / total_pred
                if success_confidences:
                    min_conf = min(success_confidences)
                    max_conf = max(success_confidences)
                    avg_conf = sum(success_confidences) / len(success_confidences)
                    print(f"{emotion:<12} {success_count:<8} {success_rate:<8.4f} {min_conf:<16.4f} {max_conf:<16.4f} {avg_conf:<16.4f}")
                else:
                    print(f"{emotion:<12} {success_count:<8} {success_rate:<8.4f} {'N/A':<16} {'N/A':<16} {'N/A':<16}")
            else:
                print(f"{emotion:<12} {'0':<8} {'0.0000':<8} {'N/A':<16} {'N/A':<16} {'N/A':<16}")
        
        # å¦‚æœæ²¡æœ‰sklearnï¼Œä½¿ç”¨æ‰‹å·¥è®¡ç®—
        if not _SK_AVAILABLE:
            print("\n" + "="*80)
            print("ğŸ“ˆ å„ç±»æƒ…ç»ªè¯¦ç»†ç»Ÿè®¡ (æ‰‹å·¥è®¡ç®—)")
            print("="*80)
            print(f"{'æƒ…ç»ªç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'æ”¯æŒæ•°':<8} {'å‡†ç¡®ç‡':<8}")
            print("-" * 70)
            
            for lbl in valid_labels:
                # è®¡ç®—TP, FP, FN
                tp = int(((y_true_np == lbl) & (y_pred_np == lbl)).sum())
                fp = int(((y_true_np != lbl) & (y_pred_np == lbl)).sum())
                fn = int(((y_true_np == lbl) & (y_pred_np != lbl)).sum())
                support = int((y_true_np == lbl).sum())
                
                # è®¡ç®—æŒ‡æ ‡
                precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
                recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
                f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
                accuracy = tp / (tp + fp) if (tp + fp) > 0 else 0.0
                
                print(f"{lbl:<12} {precision:<8.4f} {recall:<8.4f} {f1:<8.4f} {support:<8} {accuracy:<8.4f}")
        
        # è€—æ—¶ç»Ÿè®¡
        t = np.array(times, dtype=float)
        if t.size > 0:
            print("\n" + "="*80)
            print("â±ï¸ æ€§èƒ½ç»Ÿè®¡")
            print("="*80)
            print(f"å¹³å‡è€—æ—¶: {t.mean():.2f}ms")
            print(f"ä¸­ä½æ•°è€—æ—¶: {np.median(t):.2f}ms")
            print(f"æœ€å°è€—æ—¶: {t.min():.2f}ms")
            print(f"æœ€å¤§è€—æ—¶: {t.max():.2f}ms")
            print(f"æ ‡å‡†å·®: {t.std():.2f}ms")
            print(f"5åˆ†ä½: {np.percentile(t, 5):.2f}ms | 50åˆ†ä½: {np.percentile(t, 50):.2f}ms | 95åˆ†ä½: {np.percentile(t, 95):.2f}ms")
        else:
            print("\nâ±ï¸ æ€§èƒ½ç»Ÿè®¡: æ— ")
        
        # æ··æ·†çŸ©é˜µ
        if _SK_AVAILABLE:
            try:
                cm = confusion_matrix(y_true_np, y_pred_np, labels=valid_labels)
                print("\n" + "="*80)
                print("ğŸ” æ··æ·†çŸ©é˜µ")
                print("="*80)
                print("çœŸå®\\é¢„æµ‹  " + "  ".join([f"{l[:4]:>6}" for l in valid_labels]))
                print("-" * (10 + len(valid_labels) * 7))
                for i, lbl in enumerate(valid_labels):
                    print(f"{lbl:<10} " + "  ".join([f"{cm[i][j]:>6}" for j in range(len(valid_labels))]))
                
                # è®¡ç®—æ¯è¡Œçš„å‡†ç¡®ç‡
                print("\nå„ç±»åˆ«é¢„æµ‹å‡†ç¡®ç‡:")
                for i, lbl in enumerate(valid_labels):
                    row_sum = cm[i].sum()
                    if row_sum > 0:
                        accuracy = cm[i][i] / row_sum
                        print(f"  {lbl}: {accuracy:.4f} ({cm[i][i]}/{row_sum})")
                
            except Exception as e:
                print(f"\næ··æ·†çŸ©é˜µè®¡ç®—å¤±è´¥: {e}")
        
        # é”™è¯¯åˆ†æ
        print("\n" + "="*80)
        print("ğŸ” é”™è¯¯åˆ†æ")
        print("="*80)
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„é”™è¯¯ç±»å‹
        error_pairs = []
        for true_label, pred_label in zip(y_true_np, y_pred_np):
            if true_label != pred_label:
                error_pairs.append((true_label, pred_label))
        
        if error_pairs:
            from collections import Counter
            error_counter = Counter(error_pairs)
            print("æœ€å¸¸è§çš„é”™è¯¯é¢„æµ‹:")
            for (true_lbl, pred_lbl), count in error_counter.most_common(10):
                print(f"  {true_lbl} â†’ {pred_lbl}: {count}æ¬¡")
        else:
            print("ğŸ‰ æ²¡æœ‰é¢„æµ‹é”™è¯¯ï¼")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='DialogueGCNæ¨¡å‹è¯„ä¼°')
    parser.add_argument('--model_path', type=str, 
                       default='emotion_bias_angry.pkl',
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--mode', type=str, choices=['interactive', 'file'],
                       default='interactive',
                       help='è¯„ä¼°æ¨¡å¼: interactive(äº¤äº’å¼) æˆ– file(æ–‡ä»¶æ‰¹é‡è¯„ä¼°)')
    parser.add_argument('--test_file', type=str,
                       default='improved_test_data.xlsx',
                       help='æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆmode=fileæ—¶ä½¿ç”¨ï¼‰')
    parser.add_argument('--device', type=str, choices=['cuda', 'cpu', 'auto'],
                       default='auto',
                       help='è¿è¡Œè®¾å¤‡')
    parser.add_argument('--confidence_threshold', type=float, default=None,
                       help='å…¨å±€ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œéneutralæƒ…ç»ªéœ€è¶…è¿‡æ­¤é˜ˆå€¼æ‰è¢«æ¥å—ï¼Œå¦åˆ™å¼ºåˆ¶ä¸ºneutral')
    parser.add_argument('--per_emotion_thresholds', type=str, default=None,
                       help='ä¸ªæ€§åŒ–æƒ…ç»ªé˜ˆå€¼ï¼Œæ ¼å¼ï¼šHAPPY:0.35,SAD:0.40,ANGRY:0.27')
    
    args = parser.parse_args()
    
    # è§£æä¸ªæ€§åŒ–é˜ˆå€¼å‚æ•°
    per_emotion_thresholds = None
    if args.per_emotion_thresholds:
        try:
            per_emotion_thresholds = {}
            for pair in args.per_emotion_thresholds.split(','):
                emotion, threshold = pair.strip().split(':')
                per_emotion_thresholds[emotion.strip().upper()] = float(threshold.strip())
            print(f"è§£æä¸ªæ€§åŒ–é˜ˆå€¼: {per_emotion_thresholds}")
        except Exception as e:
            print(f"è§£æä¸ªæ€§åŒ–é˜ˆå€¼å¤±è´¥: {e}")
            print("è¯·ä½¿ç”¨æ ¼å¼: HAPPY:0.35,SAD:0.40,ANGRY:0.27")
            return
    
    # æ™ºèƒ½æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_path = args.model_path
    if not os.path.exists(model_path):
        # å°è¯•åœ¨å¸¸è§ä½ç½®æŸ¥æ‰¾
        possible_paths = [
            model_path,
            os.path.join('DialogueGCN', 'saved', os.path.basename(model_path)),
            os.path.join('saved', os.path.basename(model_path)),
            os.path.join('.', os.path.basename(model_path))
        ]
        
        found = False
        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                found = True
                print(f"âœ… æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
                break
        
        if not found:
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
            print("\nå¯ç”¨çš„æ¨¡å‹æ–‡ä»¶:")
            # æœç´¢å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
            search_dirs = ['.', 'DialogueGCN/saved', 'saved']
            found_models = []
            for search_dir in search_dirs:
                if os.path.exists(search_dir):
                    for file in os.listdir(search_dir):
                        if file.endswith('.pkl'):
                            full_path = os.path.join(search_dir, file)
                            if full_path not in found_models:
                                found_models.append(full_path)
                                print(f"  - {full_path}")
            
            if found_models:
                print(f"\n[æç¤º] ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŒ‡å®šæ¨¡å‹è·¯å¾„:")
                print(f"python DialogueGCN/evaluate_trained_model.py --model_path {found_models[0]}")
            return
    else:
        model_path = args.model_path
    
    # åˆ›å»ºè¯„ä¼°å™¨
    print(f"[æ¨¡å‹æ–‡ä»¶] {model_path}")
    evaluator = DialogueGCNEvaluator(
        model_path, 
        device=args.device, 
        confidence_threshold=args.confidence_threshold,
        per_emotion_thresholds=per_emotion_thresholds
    )
    
    if evaluator.model is None:
        print("[é”™è¯¯] æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œè¯„ä¼°
    if args.mode == 'interactive':
        evaluator.run_interactive()
    elif args.mode == 'file':
        evaluator.evaluate_on_file(args.test_file)

if __name__ == "__main__":
    main()

