#!/usr/bin/env python3
"""
å¤šæ¨¡å‹é›†æˆè¯„ä¼°ç³»ç»Ÿ - ä½¿ç”¨æŠ•ç¥¨æˆ–å¹³å‡ç½®ä¿¡åº¦æœºåˆ¶
æ”¯æŒåŠ è½½å¤šä¸ªè®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹è¿›è¡Œé›†æˆé¢„æµ‹
æ”¯æŒå¹¶è¡Œé¢„æµ‹ä»¥æé«˜æ€§èƒ½
"""
import sys
import os
import torch
import torch.nn as nn
import numpy as np
import time
import pandas as pd
from collections import Counter
from typing import Dict, Any, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# å¯¼å…¥BERTç›¸å…³åº“
try:
    from transformers import AutoTokenizer, AutoModel
    BERT_AVAILABLE = True
except ImportError:
    BERT_AVAILABLE = False
    print("âš ï¸ BERTåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰¹å¾æå–")

# å¯¼å…¥æ¨¡å‹
try:
    from model import DialogueGCNModel
    MODEL_AVAILABLE = True
except ImportError:
    MODEL_AVAILABLE = False
    print("âŒ æ— æ³•å¯¼å…¥DialogueGCNæ¨¡å‹")

class SingleModelPredictor:
    """å•ä¸ªæ¨¡å‹é¢„æµ‹å™¨"""
    
    def __init__(self, model_path, device, tokenizer, bert_model):
        """åˆå§‹åŒ–å•ä¸ªæ¨¡å‹é¢„æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            device: è¿è¡Œè®¾å¤‡
            tokenizer: å…±äº«çš„BERT tokenizer
            bert_model: å…±äº«çš„BERTæ¨¡å‹
        """
        self.device = device
        self.model_path = model_path
        self.model_name = os.path.basename(model_path)
        
        # æƒ…ç»ªæ ‡ç­¾æ˜ å°„
        self.emotion_map = {
            0: 'NEUTRAL',
            1: 'HAPPY',
            2: 'SAD',
            3: 'ANGRY'
        }
        
        # å…±äº«BERTæ¨¡å‹
        self.tokenizer = tokenizer
        self.bert_model = bert_model
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        
        # åŠ è½½æ¨¡å‹
        self.model = None
        self.feature_dim = 768
        self.load_model(model_path)
    
    def reset_dialogue_context(self):
        """é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡"""
        self.conversation_history = []
    
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹"""
        if not MODEL_AVAILABLE:
            print(f"âŒ [{self.model_name}] æ— æ³•å¯¼å…¥DialogueGCNæ¨¡å‹")
            return False
        
        try:
            if not os.path.exists(model_path):
                print(f"âŒ [{self.model_name}] æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model_state = checkpoint['model_state_dict']
                
                if 'feature_dim' in checkpoint:
                    feature_dim = checkpoint['feature_dim']
                else:
                    feature_dim = 768
                
                self.feature_dim = feature_dim
                
                config = checkpoint.get('config', {})
                D_m = feature_dim
                
                if D_m > 1000:
                    D_g = config.get('D_g', 200)
                    D_p = config.get('D_p', 200)
                    D_e = config.get('D_e', 150)
                    D_h = config.get('D_h', 150)
                    D_a = config.get('D_a', 100)
                    graph_h = config.get('graph_h', 150)
                else:
                    D_g = config.get('D_g', 150)
                    D_p = config.get('D_p', 150)
                    D_e = config.get('D_e', 100)
                    D_h = config.get('D_h', 100)
                    D_a = config.get('D_a', 100)
                    graph_h = config.get('graph_h', 100)
                
                self.model = DialogueGCNModel(
                    base_model='LSTM',
                    D_m=D_m,
                    D_g=D_g,
                    D_p=D_p,
                    D_e=D_e,
                    D_h=D_h,
                    D_a=D_a,
                    graph_hidden_size=graph_h,
                    n_speakers=4,
                    max_seq_len=300,
                    window_past=10,
                    window_future=10,
                    n_classes=4,
                    listener_state=False,
                    context_attention='simple',
                    dropout_rec=0.1,
                    dropout=0.2,
                    nodal_attention=False,
                    avec=False,
                    no_cuda=(self.device == 'cpu')
                )
                
                self.model.load_state_dict(model_state)
                self.model.to(self.device)
                self.model.eval()
                return True
                
            else:
                print(f"âŒ [{self.model_name}] ä¸æ”¯æŒçš„æ£€æŸ¥ç‚¹æ ¼å¼")
                return False
                
        except Exception as e:
            print(f"âŒ [{self.model_name}] æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def extract_bert_features(self, text):
        """æå–BERTç‰¹å¾"""
        if self.bert_model is None or self.tokenizer is None:
            return torch.zeros(self.feature_dim, device=self.device)
        
        try:
            text = text.strip()
            if not text:
                return torch.zeros(self.feature_dim, device=self.device)
            
            inputs = self.tokenizer(
                text,
                return_tensors='pt',
                padding=True,
                truncation=True,
                max_length=512,
                add_special_tokens=True
            )
            
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.bert_model(**inputs)
                
                if self.feature_dim == 768:
                    features = outputs.last_hidden_state[:, 0, :].squeeze(0)
                elif self.feature_dim == 2304:
                    hidden_states = outputs.last_hidden_state
                    attention_mask = inputs['attention_mask']
                    
                    cls_features = hidden_states[:, 0, :].squeeze(0)
                    
                    input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()
                    sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)
                    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)
                    mean_features = (sum_embeddings / sum_mask).squeeze(0)
                    
                    hidden_states_clone = hidden_states.clone()
                    hidden_states_clone[input_mask_expanded == 0] = -1e9
                    max_features = torch.max(hidden_states_clone, 1)[0].squeeze(0)
                    
                    features = torch.cat([cls_features, mean_features, max_features], dim=0)
                else:
                    features = outputs.last_hidden_state[:, 0, :].squeeze(0)
                    if features.size(0) != self.feature_dim:
                        if not hasattr(self, 'feature_adapter'):
                            self.feature_adapter = torch.nn.Linear(768, self.feature_dim).to(self.device)
                        features = self.feature_adapter(features)
            
            return features
            
        except Exception as e:
            print(f"âš ï¸ [{self.model_name}] BERTç‰¹å¾æå–å¤±è´¥: {e}")
            return torch.zeros(self.feature_dim, device=self.device)
    
    def predict_emotion(self, user_text, robot_text=""):
        """é¢„æµ‹æƒ…ç»ª
        
        Returns:
            DictåŒ…å«emotion, confidence, probabilities
        """
        if self.model is None:
            return None
        
        try:
            self.model.eval()
            
            # æ„å»ºå¯¹è¯åºåˆ—
            conversation = []
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€è¿‘5è½®ï¼‰
            for hist_text, hist_speaker in self.conversation_history[-5:]:
                conversation.append((hist_text, hist_speaker))
            
            # æ·»åŠ å½“å‰å¯¹è¯
            if robot_text:
                conversation.append((robot_text, 1))
            conversation.append((user_text, 0))
            
            # æå–ç‰¹å¾
            text_features = []
            speaker_features = []
            
            for text, speaker in conversation:
                text_feature = self.extract_bert_features(text)
                if text_feature.is_cuda:
                    text_feature = text_feature.cpu()
                text_features.append(text_feature.numpy())
                
                speaker_feature = [0.0] * 4
                speaker_feature[speaker] = 1.0
                speaker_features.append(speaker_feature)
            
            # è½¬æ¢ä¸ºå¼ é‡
            text_features = torch.FloatTensor(np.array(text_features)).unsqueeze(1).to(self.device)
            speaker_features = torch.FloatTensor(np.array(speaker_features)).unsqueeze(1).to(self.device)
            
            # åˆ›å»ºmask
            seq_len = text_features.shape[0]
            umask = torch.ones(seq_len).unsqueeze(1).to(self.device)
            qmask = speaker_features
            
            lengths = [seq_len]
            
            # é¢„æµ‹
            with torch.no_grad():
                log_prob, _, _, _, _ = self.model(text_features, qmask, umask, lengths)
                
                if log_prob.dim() == 2:
                    last_logits = log_prob[-1]
                else:
                    last_logits = log_prob[-1, :]
                
                probabilities = torch.exp(last_logits)
                predicted_class = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_class].item()
            
            # æ„å»ºæ¦‚ç‡å­—å…¸
            probs = {}
            for i, emotion in self.emotion_map.items():
                probs[emotion] = probabilities[i].item()
            
            # æ›´æ–°å¯¹è¯å†å²
            if robot_text:
                self.conversation_history.append((robot_text, 1))
            self.conversation_history.append((user_text, 0))
            
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            return {
                'emotion': self.emotion_map[predicted_class],
                'confidence': confidence,
                'probabilities': probs,
                'model_name': self.model_name
            }
            
        except Exception as e:
            print(f"âŒ [{self.model_name}] é¢„æµ‹å¤±è´¥: {e}")
            return None


class EnsembleModelEvaluator:
    """å¤šæ¨¡å‹é›†æˆè¯„ä¼°å™¨"""
    
    def __init__(self, model_paths: List[str], device='auto', ensemble_method='vote', parallel=True, max_workers=None):
        """åˆå§‹åŒ–é›†æˆè¯„ä¼°å™¨
        
        Args:
            model_paths: æ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            device: è®¾å¤‡ ('cuda', 'cpu', æˆ– 'auto')
            ensemble_method: é›†æˆæ–¹æ³• ('vote': æŠ•ç¥¨, 'avg_confidence': å¹³å‡ç½®ä¿¡åº¦, 'weighted_avg': åŠ æƒå¹³å‡)
            parallel: æ˜¯å¦ä½¿ç”¨å¹¶è¡Œé¢„æµ‹ (é»˜è®¤True)
            max_workers: æœ€å¤§å¹¶è¡Œworkeræ•°é‡ (é»˜è®¤ä¸ºæ¨¡å‹æ•°é‡)
        """
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if device == 'auto':
            if torch.cuda.is_available():
                self.device = 'cuda'
                print("ğŸš€ æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
            else:
                self.device = 'cpu'
                print("ğŸ’» ä½¿ç”¨CPUè¿è¡Œ")
        else:
            self.device = device
        
        self.ensemble_method = ensemble_method
        self.parallel = parallel
        self.max_workers = max_workers
        
        # çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤BERTæ¨¡å‹çš„è®¿é—®
        self.bert_lock = threading.Lock()
        
        # æƒ…ç»ªæ ‡ç­¾
        self.emotion_labels = ['NEUTRAL', 'HAPPY', 'SAD', 'ANGRY']
        
        # åˆå§‹åŒ–BERTï¼ˆæ‰€æœ‰æ¨¡å‹å…±äº«ï¼‰
        self.tokenizer = None
        self.bert_model = None
        self.load_bert()
        
        # åŠ è½½æ‰€æœ‰æ¨¡å‹
        self.models = []
        print(f"\næ­£åœ¨åŠ è½½ {len(model_paths)} ä¸ªæ¨¡å‹...")
        for i, model_path in enumerate(model_paths, 1):
            print(f"\n[{i}/{len(model_paths)}] åŠ è½½æ¨¡å‹: {model_path}")
            predictor = SingleModelPredictor(model_path, self.device, self.tokenizer, self.bert_model)
            if predictor.model is not None:
                self.models.append(predictor)
                print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè·³è¿‡æ­¤æ¨¡å‹")
        
        if len(self.models) == 0:
            print("\nâŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹ï¼")
        else:
            print(f"\nâœ… æˆåŠŸåŠ è½½ {len(self.models)}/{len(model_paths)} ä¸ªæ¨¡å‹")
            print(f"ğŸ“Š é›†æˆæ–¹æ³•: {ensemble_method}")
            if self.parallel:
                workers = self.max_workers if self.max_workers else len(self.models)
                print(f"âš¡ å¹¶è¡Œæ¨¡å¼: å¼€å¯ (æœ€å¤§{workers}ä¸ªå¹¶å‘)")
            else:
                print(f"âš™ï¸  å¹¶è¡Œæ¨¡å¼: å…³é—­ (ä¸²è¡Œæ‰§è¡Œ)")
    
    def load_bert(self):
        """åŠ è½½BERTæ¨¡å‹ï¼ˆå…±äº«ï¼‰"""
        if not BERT_AVAILABLE:
            print("âš ï¸ transformersåº“ä¸å¯ç”¨")
            return False
        
        print("æ­£åœ¨åŠ è½½chinese-roberta-wwm-extæ¨¡å‹...")
        try:
            cache_dir = "./bert_cache"
            os.makedirs(cache_dir, exist_ok=True)
            model_name = 'hfl/chinese-roberta-wwm-ext'
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert_model = AutoModel.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert_model.to(self.device)
            self.bert_model.eval()
            print("âœ… BERTæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def reset_dialogue_context(self):
        """é‡ç½®æ‰€æœ‰æ¨¡å‹çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        for model in self.models:
            model.reset_dialogue_context()
        print("ğŸ”„ æ‰€æœ‰æ¨¡å‹çš„å¯¹è¯ä¸Šä¸‹æ–‡å·²é‡ç½®")
    
    def ensemble_predict(self, user_text, robot_text="", verbose=False):
        """ä½¿ç”¨é›†æˆæ–¹æ³•é¢„æµ‹æƒ…ç»ª
        
        Args:
            user_text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            robot_text: æœºå™¨äººå›å¤æ–‡æœ¬
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
        Returns:
            DictåŒ…å«ensemble_emotion, confidence, all_predictions, method_details
        """
        if len(self.models) == 0:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
            return None
        
        # è·å–æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰
        if self.parallel:
            all_predictions = self._parallel_predict(user_text, robot_text)
        else:
            all_predictions = self._sequential_predict(user_text, robot_text)
        
        if len(all_predictions) == 0:
            print("âŒ æ‰€æœ‰æ¨¡å‹é¢„æµ‹å¤±è´¥")
            return None
        
        # æ ¹æ®é›†æˆæ–¹æ³•è¿›è¡Œèåˆ
        if self.ensemble_method == 'vote':
            return self._voting_ensemble(all_predictions, verbose)
        elif self.ensemble_method == 'avg_confidence':
            return self._average_confidence_ensemble(all_predictions, verbose)
        elif self.ensemble_method == 'weighted_avg':
            return self._weighted_average_ensemble(all_predictions, verbose)
        else:
            print(f"âš ï¸ æœªçŸ¥çš„é›†æˆæ–¹æ³•: {self.ensemble_method}ï¼Œä½¿ç”¨æŠ•ç¥¨æ³•")
            return self._voting_ensemble(all_predictions, verbose)
    
    def _sequential_predict(self, user_text, robot_text=""):
        """ä¸²è¡Œé¢„æµ‹ï¼ˆåŸå§‹æ–¹æ³•ï¼‰"""
        all_predictions = []
        for model in self.models:
            result = model.predict_emotion(user_text, robot_text)
            if result:
                all_predictions.append(result)
        return all_predictions
    
    def _parallel_predict(self, user_text, robot_text=""):
        """å¹¶è¡Œé¢„æµ‹ï¼ˆä½¿ç”¨çº¿ç¨‹æ± ï¼‰"""
        all_predictions = []
        max_workers = self.max_workers if self.max_workers else len(self.models)
        
        # åˆ›å»ºé¢„æµ‹ä»»åŠ¡
        def predict_task(model):
            """å•ä¸ªæ¨¡å‹çš„é¢„æµ‹ä»»åŠ¡"""
            try:
                return model.predict_emotion(user_text, robot_text)
            except Exception as e:
                print(f"âš ï¸ æ¨¡å‹ {model.model_name} é¢„æµ‹å‡ºé”™: {e}")
                return None
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_model = {
                executor.submit(predict_task, model): model 
                for model in self.models
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_model):
                model = future_to_model[future]
                try:
                    result = future.result()
                    if result:
                        all_predictions.append(result)
                except Exception as e:
                    print(f"âš ï¸ è·å–æ¨¡å‹ {model.model_name} é¢„æµ‹ç»“æœå¤±è´¥: {e}")
        
        return all_predictions
    
    def _voting_ensemble(self, all_predictions, verbose=False):
        """æŠ•ç¥¨é›†æˆæ–¹æ³•"""
        # ç»Ÿè®¡æ¯ä¸ªæƒ…ç»ªçš„æŠ•ç¥¨æ•°
        votes = Counter([pred['emotion'] for pred in all_predictions])
        
        # è·å–ç¥¨æ•°æœ€å¤šçš„æƒ…ç»ª
        ensemble_emotion = votes.most_common(1)[0][0]
        vote_count = votes[ensemble_emotion]
        confidence = vote_count / len(all_predictions)
        
        result = {
            'ensemble_emotion': ensemble_emotion,
            'confidence': confidence,
            'all_predictions': all_predictions,
            'method': 'vote',
            'vote_details': dict(votes),
            'total_models': len(all_predictions)
        }
        
        if verbose:
            print(f"\nğŸ“Š æŠ•ç¥¨ç»“æœ:")
            for emotion, count in votes.most_common():
                print(f"   {emotion}: {count}/{len(all_predictions)} ç¥¨ ({count/len(all_predictions)*100:.1f}%)")
        
        return result
    
    def _average_confidence_ensemble(self, all_predictions, verbose=False):
        """å¹³å‡ç½®ä¿¡åº¦é›†æˆæ–¹æ³•"""
        # è®¡ç®—æ¯ä¸ªæƒ…ç»ªçš„å¹³å‡ç½®ä¿¡åº¦
        avg_probs = {emotion: [] for emotion in self.emotion_labels}
        
        for pred in all_predictions:
            for emotion, prob in pred['probabilities'].items():
                avg_probs[emotion].append(prob)
        
        # è®¡ç®—å¹³å‡å€¼
        final_probs = {}
        for emotion, probs in avg_probs.items():
            if probs:
                final_probs[emotion] = np.mean(probs)
            else:
                final_probs[emotion] = 0.0
        
        # é€‰æ‹©å¹³å‡ç½®ä¿¡åº¦æœ€é«˜çš„æƒ…ç»ª
        ensemble_emotion = max(final_probs.items(), key=lambda x: x[1])[0]
        confidence = final_probs[ensemble_emotion]
        
        result = {
            'ensemble_emotion': ensemble_emotion,
            'confidence': confidence,
            'all_predictions': all_predictions,
            'method': 'avg_confidence',
            'avg_probabilities': final_probs,
            'total_models': len(all_predictions)
        }
        
        if verbose:
            print(f"\nğŸ“Š å¹³å‡ç½®ä¿¡åº¦:")
            for emotion, prob in sorted(final_probs.items(), key=lambda x: x[1], reverse=True):
                bar = "â–ˆ" * int(prob * 30)
                print(f"   {emotion:8}: {prob:.4f} {bar}")
        
        return result
    
    def _weighted_average_ensemble(self, all_predictions, verbose=False):
        """åŠ æƒå¹³å‡é›†æˆæ–¹æ³•ï¼ˆæƒé‡ä¸ºå„æ¨¡å‹çš„ç½®ä¿¡åº¦ï¼‰"""
        # è®¡ç®—æ¯ä¸ªæƒ…ç»ªçš„åŠ æƒç½®ä¿¡åº¦
        weighted_probs = {emotion: 0.0 for emotion in self.emotion_labels}
        total_weight = 0.0
        
        for pred in all_predictions:
            weight = pred['confidence']  # ä½¿ç”¨æ¨¡å‹è‡ªå·±çš„ç½®ä¿¡åº¦ä½œä¸ºæƒé‡
            total_weight += weight
            
            for emotion, prob in pred['probabilities'].items():
                weighted_probs[emotion] += prob * weight
        
        # å½’ä¸€åŒ–
        if total_weight > 0:
            for emotion in weighted_probs:
                weighted_probs[emotion] /= total_weight
        
        # é€‰æ‹©åŠ æƒç½®ä¿¡åº¦æœ€é«˜çš„æƒ…ç»ª
        ensemble_emotion = max(weighted_probs.items(), key=lambda x: x[1])[0]
        confidence = weighted_probs[ensemble_emotion]
        
        result = {
            'ensemble_emotion': ensemble_emotion,
            'confidence': confidence,
            'all_predictions': all_predictions,
            'method': 'weighted_avg',
            'weighted_probabilities': weighted_probs,
            'total_models': len(all_predictions),
            'total_weight': total_weight
        }
        
        if verbose:
            print(f"\nğŸ“Š åŠ æƒå¹³å‡ç½®ä¿¡åº¦:")
            for emotion, prob in sorted(weighted_probs.items(), key=lambda x: x[1], reverse=True):
                bar = "â–ˆ" * int(prob * 30)
                print(f"   {emotion:8}: {prob:.4f} {bar}")
        
        return result
    
    def run_interactive(self):
        """äº¤äº’å¼è¯„ä¼°æ¨¡å¼"""
        print("\n" + "="*80)
        print("ğŸ¯ å¤šæ¨¡å‹é›†æˆäº¤äº’å¼è¯„ä¼°")
        print("="*80)
        print(f"ä½¿ç”¨ {len(self.models)} ä¸ªè®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹è¿›è¡Œé›†æˆé¢„æµ‹")
        print(f"é›†æˆæ–¹æ³•: {self.ensemble_method}")
        print("æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡")
        print("è¾“å…¥ 'quit' é€€å‡º")
        print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("è¾“å…¥ 'method <æ–¹æ³•>' åˆ‡æ¢é›†æˆæ–¹æ³• (vote/avg_confidence/weighted_avg)")
        print("="*80)
        
        total_predictions = 0
        prediction_times = []
        emotion_counts = Counter()
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
                
                if user_input.lower() == 'quit':
                    if total_predictions > 0:
                        print("\n" + "="*60)
                        print("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
                        print("="*60)
                        print(f"æ€»é¢„æµ‹æ¬¡æ•°: {total_predictions}")
                        print(f"å¹³å‡è€—æ—¶: {np.mean(prediction_times):.2f}ms")
                        print(f"\næƒ…ç»ªåˆ†å¸ƒ:")
                        for emotion, count in emotion_counts.most_common():
                            print(f"  {emotion}: {count} ({count/total_predictions*100:.1f}%)")
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
                
                elif user_input.lower() == 'clear':
                    self.reset_dialogue_context()
                    continue
                
                elif user_input.lower().startswith('method '):
                    new_method = user_input[7:].strip()
                    if new_method in ['vote', 'avg_confidence', 'weighted_avg']:
                        self.ensemble_method = new_method
                        print(f"âœ… é›†æˆæ–¹æ³•å·²åˆ‡æ¢ä¸º: {new_method}")
                    else:
                        print(f"âš ï¸ æ— æ•ˆçš„é›†æˆæ–¹æ³•ï¼Œè¯·é€‰æ‹©: vote, avg_confidence, weighted_avg")
                    continue
                
                elif not user_input:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                    continue
                
                # é¢„æµ‹æƒ…ç»ª
                print(f"\nğŸ” æ­£åœ¨ä½¿ç”¨ {len(self.models)} ä¸ªæ¨¡å‹è¿›è¡Œé›†æˆé¢„æµ‹...")
                t0 = time.perf_counter()
                result = self.ensemble_predict(user_input, robot_text="", verbose=True)
                elapsed_ms = (time.perf_counter() - t0) * 1000.0
                
                if result:
                    ensemble_emotion = result['ensemble_emotion']
                    confidence = result['confidence']
                    
                    total_predictions += 1
                    prediction_times.append(elapsed_ms)
                    emotion_counts[ensemble_emotion] += 1
                    
                    print(f"\nğŸ¯ é›†æˆé¢„æµ‹ç»“æœ: {ensemble_emotion} (ç½®ä¿¡åº¦: {confidence:.2%})")
                    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_ms:.2f}ms")
                    
                    # æ˜¾ç¤ºå„ä¸ªæ¨¡å‹çš„é¢„æµ‹
                    print(f"\nğŸ“‹ å„æ¨¡å‹é¢„æµ‹è¯¦æƒ…:")
                    for i, pred in enumerate(result['all_predictions'], 1):
                        model_name = pred['model_name']
                        emotion = pred['emotion']
                        conf = pred['confidence']
                        match = "âœ…" if emotion == ensemble_emotion else "âŒ"
                        print(f"   {match} æ¨¡å‹{i} ({model_name}): {emotion} (ç½®ä¿¡åº¦: {conf:.2%})")
                else:
                    print("âŒ é¢„æµ‹å¤±è´¥")
                    continue
                
                # å¯é€‰çš„æœºå™¨äººå›å¤
                robot_input = input("\nğŸ¤– æœºå™¨äººå›å¤ (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
                if robot_input:
                    for model in self.models:
                        model.conversation_history.append((robot_input, 1))
                    print(f"âœ… æœºå™¨äººå›å¤å·²è®°å½•åˆ°æ‰€æœ‰æ¨¡å‹")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
    
    def evaluate_on_file(self, data_path: str = 'improved_test_data.xlsx'):
        """ä½¿ç”¨æµ‹è¯•æ–‡ä»¶è¿›è¡Œæ‰¹é‡è¯„ä¼°"""
        try:
            from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
            _SK_AVAILABLE = True
        except Exception:
            _SK_AVAILABLE = False
            print("âš ï¸ sklearnä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–è¯„ä¼°")
        
        if not os.path.exists(data_path):
            print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {data_path}")
            return
        
        try:
            if data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
            elif data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
                return
        except Exception as e:
            print(f"âŒ è¯»å–æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return
        
        required_cols = {'dialogue_id', 'speaker', 'utterance', 'emotion_label'}
        if not required_cols.issubset(set(df.columns)):
            print(f"âŒ æµ‹è¯•æ•°æ®ç¼ºå°‘å¿…è¦åˆ—")
            return
        
        df = df.copy()
        df['speaker'] = df['speaker'].astype(str)
        
        user_rows = df[(df['speaker'] == 'user') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        robot_rows = df[(df['speaker'] == 'robot') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        print(f"\nğŸ§ª å¤šæ¨¡å‹é›†æˆè¯„ä¼°...")
        print(f"æ€»è®°å½•æ•°: {len(df)} | ç”¨æˆ·(æœ‰æ ‡ç­¾): {len(user_rows)} | æœºå™¨äºº(æœ‰æ ‡ç­¾): {len(robot_rows)}")
        print(f"ä½¿ç”¨æ¨¡å‹æ•°: {len(self.models)} | é›†æˆæ–¹æ³•: {self.ensemble_method}")
        
        label_map = {
            'neutral': 'NEUTRAL',
            'happy': 'HAPPY',
            'sad': 'SAD',
            'angry': 'ANGRY'
        }
        valid_labels = ['NEUTRAL', 'HAPPY', 'SAD', 'ANGRY']
        
        y_true, y_pred, times = [], [], []
        
        # æŒ‰å¯¹è¯åˆ†ç»„
        for dialogue_id, group in df.groupby('dialogue_id', sort=False):
            print(f"\n=== å¯¹è¯ {dialogue_id} å¼€å§‹ï¼Œ{len(group)} æ¡ ===")
            self.reset_dialogue_context()
            
            group = group.reset_index(drop=True)
            for idx, row in group.iterrows():
                speaker = str(row['speaker']).strip().lower()
                utterance = str(row['utterance']) if not pd.isna(row['utterance']) else ''
                true_label_raw = row.get('emotion_label')
                true_label = '' if pd.isna(true_label_raw) else str(true_label_raw)
                
                if speaker == 'robot':
                    if utterance.strip():
                        for model in self.models:
                            model.conversation_history.append((utterance.strip(), 1))
                    
                    if true_label.strip():
                        t0 = time.perf_counter()
                        result = self.ensemble_predict(utterance, robot_text="", verbose=False)
                        elapsed_ms = (time.perf_counter() - t0) * 1000.0
                        
                        if result:
                            pred = result['ensemble_emotion']
                            confidence = result['confidence']
                        else:
                            pred = 'NEUTRAL'
                            confidence = 0.0
                        
                        mapped_true = label_map.get(true_label.lower(), true_label.upper())
                        y_true.append(mapped_true)
                        y_pred.append(pred)
                        times.append(elapsed_ms)
                        
                        match_symbol = "âœ…" if pred == mapped_true else "âŒ"
                        print(f"{match_symbol} Robot: {utterance[:50]}...")
                        print(f"   è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} (ç½®ä¿¡åº¦: {confidence:.2%}) | å®é™…: {mapped_true}")
                    continue
                
                if speaker == 'user':
                    if not true_label.strip():
                        if utterance.strip():
                            for model in self.models:
                                model.conversation_history.append((utterance.strip(), 0))
                        continue
                    
                    t0 = time.perf_counter()
                    result = self.ensemble_predict(utterance, robot_text="", verbose=False)
                    elapsed_ms = (time.perf_counter() - t0) * 1000.0
                    
                    if result:
                        pred = result['ensemble_emotion']
                        confidence = result['confidence']
                    else:
                        pred = 'NEUTRAL'
                        confidence = 0.0
                    
                    mapped_true = label_map.get(true_label.lower(), true_label.upper())
                    y_true.append(mapped_true)
                    y_pred.append(pred)
                    times.append(elapsed_ms)
                    
                    match_symbol = "âœ…" if pred == mapped_true else "âŒ"
                    print(f"{match_symbol} User: {utterance[:50]}...")
                    print(f"   è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} (ç½®ä¿¡åº¦: {confidence:.2%}) | å®é™…: {mapped_true}")
        
        # æ±‡æ€»æŒ‡æ ‡
        if not y_true:
            print("\nâŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ ‡æ³¨æ•°æ®")
            return
        
        y_true_np = np.array(y_true)
        y_pred_np = np.array(y_pred)
        accuracy = float((y_true_np == y_pred_np).mean())
        
        print("\n" + "="*80)
        print("ğŸ“Š å¤šæ¨¡å‹é›†æˆè¯„ä¼°ç»“æœæ±‡æ€»")
        print("="*80)
        print(f"é›†æˆæ–¹æ³•: {self.ensemble_method}")
        print(f"ä½¿ç”¨æ¨¡å‹æ•°: {len(self.models)}")
        print(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"æ€»æ ·æœ¬æ•°: {len(y_true)}")
        
        # å„ç±»æƒ…ç»ªçš„è¯¦ç»†ç»Ÿè®¡
        print("\n" + "="*80)
        print("ğŸ“ˆ å„ç±»æƒ…ç»ªè¯¦ç»†ç»Ÿè®¡")
        print("="*80)
        
        if _SK_AVAILABLE:
            try:
                precision, recall, f1, support = precision_recall_fscore_support(
                    y_true_np, y_pred_np, labels=valid_labels, zero_division=0
                )
                
                print(f"{'æƒ…ç»ªç±»åˆ«':<12} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'æ”¯æŒæ•°':<8}")
                print("-" * 60)
                
                for i, lbl in enumerate(valid_labels):
                    print(f"{lbl:<12} {precision[i]:<8.4f} {recall[i]:<8.4f} {f1[i]:<8.4f} {int(support[i]):<8}")
                
                macro_precision = np.mean(precision)
                macro_recall = np.mean(recall)
                macro_f1 = np.mean(f1)
                
                print("-" * 60)
                print(f"{'å®å¹³å‡':<12} {macro_precision:<8.4f} {macro_recall:<8.4f} {macro_f1:<8.4f} {'-':<8}")
                
            except Exception as e:
                print(f"  è®¡ç®—è¯¦ç»†æŒ‡æ ‡å¤±è´¥: {e}")
        
        # è€—æ—¶ç»Ÿè®¡
        t = np.array(times, dtype=float)
        if t.size > 0:
            print("\n" + "="*80)
            print("â±ï¸ æ€§èƒ½ç»Ÿè®¡")
            print("="*80)
            print(f"å¹³å‡è€—æ—¶: {t.mean():.2f}ms")
            print(f"ä¸­ä½æ•°è€—æ—¶: {np.median(t):.2f}ms")
            print(f"æœ€å°è€—æ—¶: {t.min():.2f}ms")
            print(f"æœ€å¤§è€—æ—¶: {t.max():.2f}ms")
        
        # æ··æ·†çŸ©é˜µ
        if _SK_AVAILABLE:
            try:
                cm = confusion_matrix(y_true_np, y_pred_np, labels=valid_labels)
                print("\n" + "="*80)
                print("ğŸ” æ··æ·†çŸ©é˜µ")
                print("="*80)
                print("çœŸå®\\é¢„æµ‹  " + "  ".join([f"{l[:4]:>6}" for l in valid_labels]))
                print("-" * (10 + len(valid_labels) * 7))
                for i, lbl in enumerate(valid_labels):
                    print(f"{lbl:<10} " + "  ".join([f"{cm[i][j]:>6}" for j in range(len(valid_labels))]))
            except Exception as e:
                print(f"\næ··æ·†çŸ©é˜µè®¡ç®—å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¤šæ¨¡å‹é›†æˆè¯„ä¼°')
    parser.add_argument('--model_paths', type=str, nargs='+', required=True,
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰')
    parser.add_argument('--mode', type=str, choices=['interactive', 'file'],
                       default='interactive',
                       help='è¯„ä¼°æ¨¡å¼: interactive(äº¤äº’å¼) æˆ– file(æ–‡ä»¶æ‰¹é‡è¯„ä¼°)')
    parser.add_argument('--test_file', type=str,
                       default='improved_test_data.xlsx',
                       help='æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆmode=fileæ—¶ä½¿ç”¨ï¼‰')
    parser.add_argument('--device', type=str, choices=['cuda', 'cpu', 'auto'],
                       default='auto',
                       help='è¿è¡Œè®¾å¤‡')
    parser.add_argument('--ensemble_method', type=str, 
                       choices=['vote', 'avg_confidence', 'weighted_avg'],
                       default='vote',
                       help='é›†æˆæ–¹æ³•: vote(æŠ•ç¥¨), avg_confidence(å¹³å‡ç½®ä¿¡åº¦), weighted_avg(åŠ æƒå¹³å‡)')
    parser.add_argument('--parallel', action='store_true', default=True,
                       help='ä½¿ç”¨å¹¶è¡Œé¢„æµ‹ï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--no-parallel', dest='parallel', action='store_false',
                       help='ç¦ç”¨å¹¶è¡Œé¢„æµ‹ï¼Œä½¿ç”¨ä¸²è¡Œæ¨¡å¼')
    parser.add_argument('--max-workers', type=int, default=None,
                       help='æœ€å¤§å¹¶è¡Œworkeræ•°é‡ï¼ˆé»˜è®¤ä¸ºæ¨¡å‹æ•°é‡ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    valid_model_paths = []
    for model_path in args.model_paths:
        if os.path.exists(model_path):
            valid_model_paths.append(model_path)
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹: {model_path}")
        else:
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {model_path}")
    
    if len(valid_model_paths) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶")
        return
    
    print(f"\nå°†ä½¿ç”¨ {len(valid_model_paths)} ä¸ªæ¨¡å‹è¿›è¡Œé›†æˆè¯„ä¼°")
    
    # åˆ›å»ºé›†æˆè¯„ä¼°å™¨
    evaluator = EnsembleModelEvaluator(
        valid_model_paths, 
        device=args.device,
        ensemble_method=args.ensemble_method,
        parallel=args.parallel,
        max_workers=args.max_workers
    )
    
    if len(evaluator.models) == 0:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ¨¡å‹ï¼Œæ— æ³•ç»§ç»­")
        return
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œè¯„ä¼°
    if args.mode == 'interactive':
        evaluator.run_interactive()
    elif args.mode == 'file':
        evaluator.evaluate_on_file(args.test_file)

if __name__ == "__main__":
    main()

