#!/usr/bin/env python3
"""
æœ€ç»ˆæ··åˆæƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ
ç»“åˆDialogueGCNå’Œå¤§æ¨¡å‹ï¼Œå®ç°æ™ºèƒ½æƒ…ç»ªåˆ¤æ–­
"""
import sys
sys.path.append('DialogueGCN')
sys.path.append('code')

import torch
import torch.nn as nn
import numpy as np
import os
import re
import jieba
import time
import json
import uuid
from collections import Counter, deque
from typing import Dict, Any, List, Optional, Tuple
import pandas as pd
import numpy as np

# å¯¼å…¥æ•°æ®åº“ç›¸å…³
try:
    import pymysql
    MYSQL_AVAILABLE = True
except ImportError:
    MYSQL_AVAILABLE = False
    print("âš ï¸ PyMySQLåº“æœªå®‰è£…ï¼Œå°†æ— æ³•å­˜å‚¨åˆ°æ•°æ®åº“")

# å¯¼å…¥BERTç›¸å…³åº“
try:
    from transformers import AutoTokenizer, AutoModel
    BERT_AVAILABLE = True
except ImportError:
    BERT_AVAILABLE = False
    print("âš ï¸ BERTåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰¹å¾æå–")

# å¯¼å…¥å¤§æ¨¡å‹ç›¸å…³
try:
    from volcenginesdkarkruntime import Ark
    ARK_AVAILABLE = True
except ImportError:
    ARK_AVAILABLE = False
    print("âš ï¸ å¤§æ¨¡å‹åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–å¤§æ¨¡å‹æ¨¡æ‹Ÿ")

class SimpleDialogueGCN(nn.Module):
    """ç®€åŒ–çš„DialogueGCNæ¨¡å‹"""
    
    def __init__(self, input_dim=768, hidden_dim=200, num_classes=5, dropout=0.5):
        super(SimpleDialogueGCN, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_classes = num_classes
        
        # æ–‡æœ¬ç¼–ç å™¨ (LSTM)
        self.text_encoder = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=2,
            bidirectional=True,
            dropout=dropout,
            batch_first=True
        )
        
        # è¯´è¯è€…ç¼–ç å™¨
        self.speaker_encoder = nn.Linear(2, hidden_dim)
        
        # è¯´è¯è€…æŠ•å½±å±‚
        self.speaker_projection = nn.Linear(hidden_dim, hidden_dim * 2)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_dim * 2,
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, num_classes)
        )
        
    def forward(self, text_features, visual_features, audio_features, speaker_features, mask):
        """å‰å‘ä¼ æ’­"""
        # æ£€æŸ¥text_featuresçš„ç»´åº¦
        if text_features.dim() == 2:
            batch_size = text_features.shape[0]
            seq_len = 1
            text_features = text_features.unsqueeze(1)
        elif text_features.dim() == 3:
            batch_size, seq_len, _ = text_features.shape
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„text_featuresç»´åº¦: {text_features.dim()}")
        
        # æ–‡æœ¬ç¼–ç 
        text_output, _ = self.text_encoder(text_features)
        
        # è¯´è¯è€…ç¼–ç 
        speaker_output = self.speaker_encoder(speaker_features)
        speaker_output = self.speaker_projection(speaker_output)
        
        # ç‰¹å¾èåˆ
        combined_features = text_output + speaker_output
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attended_features, _ = self.attention(
            combined_features, combined_features, combined_features,
            key_padding_mask=~mask.bool() if mask is not None else None
        )
        
        # åˆ†ç±»
        logits = self.classifier(attended_features)
        
        # åº”ç”¨æ©ç 
        if mask is not None:
            min_len = min(mask.shape[1], logits.shape[1])
            mask = mask[:, :min_len]
            logits = logits[:, :min_len, :]
            mask_expanded = mask.unsqueeze(-1).expand_as(logits)
            logits = logits * mask_expanded
        
        return logits

class LargeModelClient:
    """å¤§æ¨¡å‹å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.client = None
        if ARK_AVAILABLE:
            try:
                os.environ["ARK_API_KEY"] = "be62df6f-1828-47a4-84f1-2932c111bc64"
                # ä¼˜åŒ–è¶…æ—¶è®¾ç½®ï¼Œå‡å°‘åˆ°30ç§’
                self.client = Ark(api_key=os.environ.get("ARK_API_KEY"), timeout=30)
            except Exception as e:
                print(f"âš ï¸ å¤§æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
                self.client = None
    
    def analyze_emotion(self, text: str, context: str = "") -> Dict[str, Any]:
        """ä½¿ç”¨å¤§æ¨¡å‹åˆ†ææƒ…ç»ªï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        if not self.client:
            return self._simulate_large_model(text)
        
        try:
            # å®Œå…¨å‚è€ƒemotion_based_text.pyçš„ç®€åŒ–æ¶ˆæ¯ç»“æ„
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»å™¨ã€‚å¿…é¡»åªè¾“å‡ºä¸€ä¸ªä¸¥æ ¼çš„ JSON å¯¹è±¡ï¼Œä¸è¦è¾“å‡ºå¤šä½™æ–‡æœ¬ã€è§£é‡Šæˆ–åå¼•å·ã€‚
                    ## ä½ çš„ä»»åŠ¡
                    æ ¹æ®ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ï¼Œåˆ¤æ–­å…¶è¡¨è¾¾çš„æƒ…æ„Ÿã€‚
                    ## è¾“å‡ºè¦æ±‚
                    1. è¾“å‡ºå¿…é¡»ä¸ºä¸¥æ ¼ JSONï¼Œä¸”ä»…åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
                    {"emotion": string, "reason": string}
                    2. `emotion` ä» ["NEUTRAL", "SAD", "ANGRY", "HAPPY"ï¼Œ "SURPRISE"] ä¸­é€‰æ‹©ã€‚
                    3. `reason` å­—æ®µæä¾›ç®€è¦åˆ¤æ–­ä¾æ®ï¼ˆ20å­—å†…ï¼‰ã€‚
                    4. è‹¥éš¾ä»¥åˆ¤æ–­ï¼Œç»Ÿä¸€åˆ¤ä¸º"NEUTRAL"ã€‚
                    """
                },
                {
                    "role": "user",
                    "content": f"å¾…åˆ†ç±»æ–‡æœ¬ï¼šã€Œ{text}ã€"
                }
            ]
            
            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œç®€åŒ–æ·»åŠ æ–¹å¼
            if context:
                messages[1]["content"] = f"ä¸Šä¸‹æ–‡ï¼š{context}\nå¾…åˆ†ç±»æ–‡æœ¬ï¼šã€Œ{text}ã€"
            
            # æ·»åŠ æ€§èƒ½è®¡æ—¶
            t0 = time.perf_counter()
            
            response = self.client.chat.completions.create(
                model="doubao-seed-1.6-250615",
                messages=messages,
                thinking={"type": "disabled"},
                response_format={"type": "json_object"}
            )
            
            elapsed_ms = round((time.perf_counter() - t0) * 1000, 2)
            print(f"â±ï¸ å¤§æ¨¡å‹å“åº”æ—¶é—´: {elapsed_ms}ms")
            
            # è§£æå“åº”ï¼Œå®Œå…¨å‚è€ƒemotion_based_text.pyçš„è§£ææ–¹å¼
            msg = response.choices[0].message
            try:
                result = getattr(msg, "parsed", None) or json.loads(getattr(msg, "content", msg))
            except Exception as e:
                print(f"JSON è§£æå¤±è´¥: {e}")
                result = {"emotion": "NEUTRAL", "reason": "è§£æå¤±è´¥"}
            
            # ç¡®ä¿æƒ…ç»ªæ ‡ç­¾æ­£ç¡®
            emotion = str(result.get("emotion", "NEUTRAL")).upper()
            if emotion not in ["NEUTRAL", "SAD", "ANGRY", "HAPPY"]:
                emotion = "NEUTRAL"
            
            # ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒï¼ˆåŸºäºæƒ…ç»ªæ ‡ç­¾ï¼‰
            probs_filled = {k: 0.1 for k in ["NEUTRAL", "SAD", "ANGRY", "HAPPY"]}
            probs_filled[emotion] = 0.7  # ä¸»è¦æƒ…ç»ªå 70%
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = 0.7 if emotion != "NEUTRAL" else 0.5
            
            return {
                "emotion": emotion,
                "confidence": confidence,
                "emotion_probs": probs_filled,
                "reason": str(result.get("reason", ""))[:30],
                "source": "large_model",
                "response_time_ms": elapsed_ms
            }
            
        except Exception as e:
            print(f"âš ï¸ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
            print(f"   å›é€€åˆ°æ¨¡æ‹Ÿå¤§æ¨¡å‹")
            return self._simulate_large_model(text)
    
class FinalEmotionSystem:
    """æœ€ç»ˆæ··åˆæƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ"""
    
    def __init__(self, model_path, device='auto', session_id=None):
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        if device == 'auto':
            if torch.cuda.is_available():
                self.device = 'cuda'
                print("ğŸš€ æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUåŠ é€Ÿ")
            else:
                self.device = 'cpu'
                print("ğŸ’» ä½¿ç”¨CPUè¿è¡Œ")
        else:
            self.device = device
        
        # æƒ…ç»ªæ ‡ç­¾æ˜ å°„
        self.emotion_map = {
            0: 'NEUTRAL',    # neutral
            1: 'HAPPY',      # happy
            2: 'SAD',        # sad
            3: 'ANGRY',      # angry
            4: 'SURPRISE'    # surprise
        }
        
        self.reverse_emotion_map = {v: k for k, v in self.emotion_map.items()}
        
        # å¯¹è¯å†å²
        self.conversation_history = []
        self.turn_count = 0
        self.previous_gcn_probs = None
        
        # ä¼šè¯ID
        self.session_id = session_id or str(uuid.uuid4())
        
        # æ•°æ®åº“ç›¸å…³
        self.db_available = MYSQL_AVAILABLE
        if self.db_available:
            self.init_database()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.model = None
        self.tokenizer = None
        self.bert_model = None
        self.large_model_client = LargeModelClient()
        
        # åŠ è½½æ¨¡å‹å’ŒBERT
        self.load_model(model_path)
        self.load_bert()
    
    def reset_dialogue_context(self):
        """é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡å†å²çª—å£"""
        self.conversation_history = []
        self.turn_count = 0
        self.previous_gcn_probs = None
        # é‡ç½®å½“å‰å¯¹è¯ID
        if hasattr(self, 'current_dialogue_id'):
            delattr(self, 'current_dialogue_id')
        print("ğŸ”„ å¯¹è¯ä¸Šä¸‹æ–‡å·²é‡ç½®")
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            conn = self._mysql_conn()
            with conn.cursor() as c:
                # åˆ›å»ºturn_emotionsè¡¨
                c.execute("""
                    CREATE TABLE IF NOT EXISTS turn_emotions (
                        session_id VARCHAR(128) NOT NULL,
                        turn_id VARCHAR(128) NOT NULL,
                        role VARCHAR(32) NOT NULL,
                        text TEXT,
                        emotion VARCHAR(16) NOT NULL,
                        probs_json JSON,
                        confidence DOUBLE,
                        source VARCHAR(64),
                        reason TEXT,
                        created_at DOUBLE,
                        INDEX idx_turn_session(session_id),
                        INDEX idx_turn_time(created_at)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """)
                
                # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
                try:
                    c.execute("ALTER TABLE turn_emotions ADD COLUMN source VARCHAR(64) AFTER confidence")
                    print("âœ… æ·»åŠ sourceå­—æ®µ")
                except Exception:
                    pass  # å­—æ®µå·²å­˜åœ¨
                
                try:
                    c.execute("ALTER TABLE turn_emotions ADD COLUMN reason TEXT AFTER source")
                    print("âœ… æ·»åŠ reasonå­—æ®µ")
                except Exception:
                    pass  # å­—æ®µå·²å­˜åœ¨
                
                # åˆ›å»ºsession_stateè¡¨
                c.execute("""
                    CREATE TABLE IF NOT EXISTS session_state (
                        session_id VARCHAR(128) NOT NULL PRIMARY KEY,
                        stable_emotion VARCHAR(16) NOT NULL,
                        stable_confidence DOUBLE,
                        last_updated_at DOUBLE
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """)
                
                # åˆ›å»ºshift_eventsè¡¨
                c.execute("""
                    CREATE TABLE IF NOT EXISTS shift_events (
                        session_id VARCHAR(128) NOT NULL,
                        from_emotion VARCHAR(16) NOT NULL,
                        to_emotion VARCHAR(16) NOT NULL,
                        at_turn_id VARCHAR(128) NOT NULL,
                        evidence JSON,
                        delta_conf DOUBLE,
                        created_at DOUBLE,
                        INDEX idx_shift_session(session_id),
                        INDEX idx_shift_time(created_at)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
                """)
            
            conn.close()
            print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.db_available = False
    
    def _mysql_conn(self):
        """è·å–MySQLè¿æ¥"""
        if not MYSQL_AVAILABLE:
            raise RuntimeError("æœªå®‰è£… PyMySQLï¼Œè¯·å…ˆå®‰è£…: pip install pymysql")
        
        host = os.environ.get("MYSQL_HOST", "127.0.0.1")
        port = int(os.environ.get("MYSQL_PORT", "3306"))
        user = os.environ.get("MYSQL_USER", "root")
        password = os.environ.get("MYSQL_PASSWORD", "HYXjy9920")
        database = os.environ.get("MYSQL_DB", "logs")
        charset = "utf8mb4"
        
        return pymysql.connect(
            host=host, port=port, user=user, password=password, 
            database=database, charset=charset, autocommit=True
        )
    
    def save_emotion_result(self, turn_id, role, text, emotion, confidence, probabilities, source, reason):
        """ä¿å­˜æƒ…ç»ªè¯†åˆ«ç»“æœåˆ°æ•°æ®åº“"""
        if not self.db_available:
            return
        
        try:
            conn = self._mysql_conn()
            with conn.cursor() as c:
                c.execute("""
                    INSERT INTO turn_emotions(
                        session_id, turn_id, role, text, emotion, probs_json, 
                        confidence, source, reason, created_at
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    self.session_id,
                    turn_id,
                    role,
                    text,
                    emotion,
                    json.dumps(probabilities, ensure_ascii=False),
                    confidence,
                    source,
                    reason,
                    time.time()
                ))
            conn.close()
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æƒ…ç»ªç»“æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")
    
    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„DialogueGCNæ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½DialogueGCNæ¨¡å‹...")
        
        try:
            # åˆ›å»ºæ¨¡å‹å®ä¾‹ - ä½¿ç”¨ä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€è‡´çš„hidden_dim=100
            self.model = SimpleDialogueGCN(
                input_dim=768,
                hidden_dim=200,  # ä¿®æ”¹ä¸º100ä»¥åŒ¹é…é¢„è®­ç»ƒæ¨¡å‹
                num_classes=5,
                dropout=0.5
            )
            # å…ˆå°†æ¨¡å‹è¿ç§»åˆ°ç›®æ ‡è®¾å¤‡ï¼Œç¡®ä¿åç»­æƒé‡/ç¼“å†²åŒºè®¾å¤‡ä¸€è‡´
            self.model.to(self.device)

            # åŠ è½½æ¨¡å‹æƒé‡
            if os.path.exists(model_path):
                state_dict = torch.load(model_path, map_location=self.device, weights_only=False)
                self.model.load_state_dict(state_dict)
                print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
            else:
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False
            
            self.model.to(self.device)
            self.model.eval()
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def load_bert(self):
        """åŠ è½½chinese-roberta-wwm-extæ¨¡å‹"""
        if not BERT_AVAILABLE:
            print("âš ï¸ transformersåº“ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰¹å¾æå–")
            return False
        print("æ­£åœ¨åŠ è½½chinese-roberta-wwm-extæ¨¡å‹...")
        try:
            cache_dir = "./bert_cache"
            os.makedirs(cache_dir, exist_ok=True)
            model_name = 'hfl/chinese-roberta-wwm-ext'
            self.tokenizer = AutoTokenizer.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert_model = AutoModel.from_pretrained(
                model_name,
                cache_dir=cache_dir,
                local_files_only=False
            )
            self.bert_model.to(self.device)
            self.bert_model.eval()
            print("âœ… chinese-roberta-wwm-extæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ BERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def extract_bert_features(self, text):
        """æå–BERTç‰¹å¾"""
        if self.bert_model is None or self.tokenizer is None:
            return self.extract_simple_features(text)
        
        try:
            text = text.strip()
            if not text:
                return torch.zeros(768, device=self.device)
            
            inputs = self.tokenizer(
                text, 
                return_tensors='pt', 
                padding=True, 
                truncation=True, 
                max_length=512,
                add_special_tokens=True
            )
            
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.bert_model(**inputs)
                features = outputs.last_hidden_state[:, 0, :]
            
            return features.squeeze(0)
            
        except Exception as e:
            print(f"âš ï¸ BERTç‰¹å¾æå–å¤±è´¥: {e}")
            return self.extract_simple_features(text)
    
    # def extract_simple_features(self, text):
    #     """ç®€åŒ–ç‰¹å¾æå–"""
    #     text_lower = text.lower()
        
    #     emotion_keywords = {
    #         'happy': ['å¼€å¿ƒ', 'é«˜å…´', 'å¿«ä¹', 'å…´å¥‹', 'æ»¡æ„', 'å–œæ¬¢', 'çˆ±', 'å¥½', 'æ£’', 'èµ', 'å“ˆå“ˆ', 'å˜¿å˜¿', 'è€¶', 'å¤ªæ£’äº†', 'å®Œç¾'],
    #         'sad': ['éš¾è¿‡', 'ä¼¤å¿ƒ', 'ç—›è‹¦', 'å¤±æœ›', 'æ²®ä¸§', 'å“­', 'æ³ª', 'å', 'å·®', 'ç³Ÿç³•', 'å”‰', 'å”‰å£°å¹æ°”', 'éƒé—·', 'çƒ¦èº'],
    #         'angry': ['ç”Ÿæ°”', 'æ„¤æ€’', 'æ¼ç«', 'è®¨åŒ', 'æ¨', 'çƒ¦', 'æ°”', 'æ€’', 'ç«', 'æš´èº', 'å¯æ¶', 'è¯¥æ­»', 'æ··è›‹', 'æ°”æ­»æˆ‘äº†'],
    #         'surprise': ['æƒŠè®¶', 'éœ‡æƒŠ', 'æ„å¤–', 'æ²¡æƒ³åˆ°', 'ç«Ÿç„¶', 'å±…ç„¶', 'å¤©å“ª', 'å“‡', 'å“¦', 'å•Š', 'ä»€ä¹ˆ', 'çœŸçš„å—', 'ä¸ä¼šå§']
    #     }
        
    #     emotion_scores = {emotion: 0.0 for emotion in emotion_keywords.keys()}
    #     for emotion, keywords in emotion_keywords.items():
    #         for keyword in keywords:
    #             if keyword in text_lower:
    #                 emotion_scores[emotion] += 1.0
        
    #     if max(emotion_scores.values()) > 0:
    #         main_emotion = max(emotion_scores, key=emotion_scores.get)
    #     else:
    #         main_emotion = 'neutral'
        
    #     # ç”Ÿæˆç‰¹å¾å‘é‡
    #     feature = np.zeros(768)
        
    #     emotion_centers = {
    #         'happy': 0.8,
    #         'sad': -0.8,
    #         'angry': -0.6,
    #         'surprise': 0.4,
    #         'neutral': 0.0
    #     }
        
    #     center = emotion_centers[main_emotion]
    #     intensity = min(max(emotion_scores.values()) / 5.0, 1.0)
        
    #     # å‰100ç»´ï¼šåŸºäºä¸»è¦æƒ…ç»ª
    #     for i in range(100):
    #         feature[i] = center * intensity + np.random.normal(0, 0.1)
        
    #     # 100-200ç»´ï¼šåŸºäºæƒ…ç»ªåˆ†å¸ƒ
    #     for i, (emotion, score) in enumerate(emotion_scores.items()):
    #         start_idx = 100 + i * 25
    #         end_idx = start_idx + 25
    #         for j in range(start_idx, min(end_idx, 200)):
    #             feature[j] = score / 5.0 + np.random.normal(0, 0.05)
        
    #     # 200-300ç»´ï¼šåŸºäºæ–‡æœ¬ç‰¹å¾
    #     text_length = len(text)
    #     word_count = len(jieba.lcut(text))
        
    #     for i in range(200, 300):
    #         if i < 250:
    #             feature[i] = min(text_length / 100.0, 1.0) + np.random.normal(0, 0.05)
    #         else:
    #             feature[i] = min(word_count / 50.0, 1.0) + np.random.normal(0, 0.05)
        
    #     # 300-768ç»´ï¼šéšæœºç‰¹å¾
    #     for i in range(300, 768):
    #         feature[i] = np.random.normal(0, 0.2)
        
    #     return torch.FloatTensor(feature).to(self.device)
    
    def get_dialoguegcn_prediction(self, user_text, robot_text=""):
        """è·å–DialogueGCNé¢„æµ‹ç»“æœ"""
        if self.model is None:
            return None
        
        try:
            # åŒé‡ä¿é™©ï¼šç¡®ä¿æ¨¡å‹å·²åœ¨ç›®æ ‡è®¾å¤‡ä¸Š
            self.model.to(self.device)
            self.model.eval()
            # æ„å»ºå¯¹è¯åºåˆ—
            conversation = []
            
            # æ·»åŠ å†å²å¯¹è¯
            for hist_text, hist_speaker in self.conversation_history[-5:]:
                conversation.append((hist_text, hist_speaker))
            
            # å¦‚æœæ˜¯ç¬¬ä¸€å¥è¯ï¼ˆæ²¡æœ‰å†å²ï¼‰ï¼Œæ·»åŠ ä¸€ä¸ªä¸­æ€§çš„è™šæ‹Ÿä¸Šä¸‹æ–‡
            # è¿™å¯ä»¥å‡å°‘æ¨¡å‹å¯¹ç¬¬ä¸€å¥è¯çš„SADåå‘
            if len(conversation) == 0 and not robot_text:
                # æ·»åŠ ä¸€ä¸ªä¸­æ€§çš„æœºå™¨äººé—®å€™ä½œä¸ºè™šæ‹Ÿä¸Šä¸‹æ–‡
                virtual_context = "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚"
                conversation.append((virtual_context, 1))  # robot
            
            # æ·»åŠ å½“å‰å¯¹è¯
            if robot_text:
                conversation.append((robot_text, 1))  # robot
            conversation.append((user_text, 0))  # user
            
            # æå–ç‰¹å¾
            text_features = []
            speaker_features = []
            
            for text, speaker in conversation:
                text_feature = self.extract_bert_features(text)
                if text_feature.is_cuda:
                    text_feature = text_feature.cpu()
                text_features.append(text_feature.numpy())
                
                speaker_feature = [0.0, 0.0]
                speaker_feature[speaker] = 1.0
                speaker_features.append(speaker_feature)
            
            # è½¬æ¢ä¸ºå¼ é‡
            text_features = torch.FloatTensor(np.array(text_features)).unsqueeze(0).to(self.device)
            speaker_features = torch.FloatTensor(np.array(speaker_features)).unsqueeze(0).to(self.device)
            
            # åˆ›å»ºè™šæ‹Ÿç‰¹å¾
            seq_len = text_features.shape[1]
            visual_features = torch.zeros(1, seq_len, 100).to(self.device)
            audio_features = torch.zeros(1, seq_len, 100).to(self.device)
            mask = torch.ones(1, seq_len).to(self.device)
            
            # é¢„æµ‹
            with torch.no_grad():
                logits = self.model(text_features, visual_features, audio_features, speaker_features, mask)
                last_logits = logits[0, -1, :]
                probabilities = torch.softmax(last_logits, dim=0)
                predicted_class = torch.argmax(probabilities).item()
                confidence = probabilities[predicted_class].item()
            
            # æ„å»ºæ¦‚ç‡å­—å…¸
            probs = {}
            for i, emotion in self.emotion_map.items():
                probs[emotion] = probabilities[i].item()
            
            return {
                'emotion': self.emotion_map[predicted_class],
                'confidence': confidence,
                'probabilities': probs,
                'source': 'dialoguegcn'
            }
            
        except Exception as e:
            print(f"âŒ DialogueGCNé¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def update_gcn_confidence(self, gcn_result, large_model_result):
        """é€‚åº¦æ›´æ–°DialogueGCNçš„ç½®ä¿¡åº¦"""
        if not gcn_result or not large_model_result:
            return gcn_result
        
        # è·å–å¤§æ¨¡å‹ç»“æœ
        lm_emotion = large_model_result['emotion']
        lm_confidence = large_model_result['confidence']
        
        # é€‚åº¦è°ƒæ•´GCNç»“æœï¼Œä¸è¦è¿‡åº¦ä¿®æ”¹
        updated_probs = gcn_result['probabilities'].copy()
        
        # å¦‚æœå¤§æ¨¡å‹ç»“æœä¸GCNä¸åŒï¼Œé€‚åº¦è°ƒæ•´
        if lm_emotion != gcn_result['emotion']:
            # å¢åŠ å¤§æ¨¡å‹é¢„æµ‹çš„æƒ…ç»ªæ¦‚ç‡
            adjustment = min(0.15, lm_confidence * 0.2)  # æœ€å¤šè°ƒæ•´15%
            updated_probs[lm_emotion] = min(1.0, updated_probs[lm_emotion] + adjustment)
            
            # ç›¸åº”å‡å°‘å…¶ä»–æƒ…ç»ªçš„æ¦‚ç‡
            total_other = sum(updated_probs[emotion] for emotion in updated_probs if emotion != lm_emotion)
            if total_other > 0:
                for emotion in updated_probs:
                    if emotion != lm_emotion:
                        updated_probs[emotion] *= (1 - adjustment / total_other)
        
        # é‡æ–°è®¡ç®—ç½®ä¿¡åº¦å’Œé¢„æµ‹æƒ…ç»ª
        max_emotion = max(updated_probs, key=updated_probs.get)
        max_confidence = updated_probs[max_emotion]
        
        return {
            'emotion': max_emotion,
            'confidence': max_confidence,
            'probabilities': updated_probs,
            'source': 'dialoguegcn_updated'
        }
    
    def predict_emotion(self, user_text, robot_text="", dialogue_id=None):
        """æ··åˆæƒ…ç»ªé¢„æµ‹ä¸»å‡½æ•° - åœ¨ç”¨æˆ·è¾“å…¥åç«‹å³åˆ¤æ–­æƒ…ç»ª
        
        Args:
            user_text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            robot_text: æœºå™¨äººå›å¤æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
            dialogue_id: å¯¹è¯IDï¼Œå¦‚æœæä¾›ä¸”ä¸å½“å‰ä¸åŒï¼Œå°†é‡ç½®ä¸Šä¸‹æ–‡
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡
        if dialogue_id is not None and hasattr(self, 'current_dialogue_id'):
            if self.current_dialogue_id != dialogue_id:
                print(f"ğŸ”„ æ£€æµ‹åˆ°æ–°å¯¹è¯ID: {dialogue_id}ï¼Œé‡ç½®ä¸Šä¸‹æ–‡å†å²çª—å£")
                self.reset_dialogue_context()
                self.current_dialogue_id = dialogue_id
        elif dialogue_id is not None:
            self.current_dialogue_id = dialogue_id
        
        self.turn_count += 1
        turn_id = str(int(time.time() * 1000))
        
        # 1. ç¬¬ä¸€å¥è¯éƒ½é»˜è®¤ç”¨å¤§æ¨¡å‹æ¥åˆ¤æ–­
        if self.turn_count == 1:
            print("ğŸ”„ ç¬¬ä¸€å¥è¯ï¼Œä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­...")
            context = " | ".join([f"{'æœºå™¨äºº' if speaker == 1 else 'ç”¨æˆ·'}: {text}" for text, speaker in self.conversation_history[-8:]])
            if robot_text:
                context += f" | æœºå™¨äºº: {robot_text}"
            
            print(f"ğŸ“¤ å‘é€ç»™å¤§æ¨¡å‹çš„å†…å®¹:")
            print(f"   å½“å‰ç”¨æˆ·è¾“å…¥: {user_text}")
            print(f"   ä¸Šä¸‹æ–‡å†å²: {context if context else 'æ— '}")
            
            result = self.large_model_client.analyze_emotion(user_text, context)
            
            # åŒæ—¶è·å–DialogueGCNç»“æœç”¨äºåç»­æ¯”è¾ƒ
            gcn_result = self.get_dialoguegcn_prediction(user_text, robot_text)
            if gcn_result:
                # ä¿å­˜DialogueGCNæ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
                self.previous_gcn_probs = gcn_result['probabilities'].copy()
                print(f"ğŸ” åŒæ—¶è·å–DialogueGCNç»“æœç”¨äºåç»­æ¯”è¾ƒ: {gcn_result['emotion']} (ç½®ä¿¡åº¦: {gcn_result['confidence']:.2%})")
            
            # æ›´æ–°å¯¹è¯å†å²
            if robot_text:
                self.conversation_history.append((robot_text, 1))
            self.conversation_history.append((user_text, 0))
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.save_emotion_result(
                turn_id, "user", user_text, result['emotion'], 
                result['confidence'], result['emotion_probs'], 
                'large_model_first_turn', result['reason']
            )
            
            return {
                'emotion': result['emotion'],
                'confidence': result['confidence'],
                'probabilities': result['emotion_probs'],
                'source': 'large_model_first_turn',
                'reason': result['reason']
            }
        
        # è·å–DialogueGCNé¢„æµ‹ç»“æœ
        gcn_result = self.get_dialoguegcn_prediction(user_text, robot_text)
        if not gcn_result:
            print("âŒ DialogueGCNé¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨å¤§æ¨¡å‹")
            context = " | ".join([f"{'æœºå™¨äºº' if speaker == 1 else 'ç”¨æˆ·'}: {text}" for text, speaker in self.conversation_history[-8:]])
            
            print(f"ğŸ“¤ å‘é€ç»™å¤§æ¨¡å‹çš„å†…å®¹:")
            print(f"   å½“å‰ç”¨æˆ·è¾“å…¥: {user_text}")
            print(f"   ä¸Šä¸‹æ–‡å†å²: {context if context else 'æ— '}")
            
            result = self.large_model_client.analyze_emotion(user_text, context)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.save_emotion_result(
                turn_id, "user", user_text, result['emotion'], 
                result['confidence'], result['emotion_probs'], 
                'large_model_fallback', result['reason']
            )
            
            return {
                'emotion': result['emotion'],
                'confidence': result['confidence'],
                'probabilities': result['emotion_probs'],
                'source': 'large_model_fallback',
                'reason': result['reason']
            }
        
        gcn_emotion = gcn_result['emotion']
        gcn_probs = gcn_result['probabilities']
        neutral_prob = gcn_probs.get('NEUTRAL', 0.0)
        
        # 2. DialogueGCNåˆ¤å®šç»“æœä¸ä¸ºneutralæ—¶æ‰ä¸ºdialoguegcnç»“æœ
        if gcn_emotion != 'NEUTRAL':
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æƒ…ç»ªä¸Šå‡3%
            other_emotion_increased = False
            if self.previous_gcn_probs:
                print(f"ğŸ” æ£€æŸ¥å…¶ä»–æƒ…ç»ªæ˜¯å¦ä¸Šå‡3%:")
                for emotion in gcn_probs:
                    if emotion != gcn_emotion:  # æ£€æŸ¥é™¤å½“å‰é¢„æµ‹æƒ…ç»ªå¤–çš„å…¶ä»–æƒ…ç»ª
                        current_prob = gcn_probs.get(emotion, 0.0)
                        previous_prob = self.previous_gcn_probs.get(emotion, 0.0)
                        change = current_prob - previous_prob
                        print(f"   {emotion}: {previous_prob:.3f} -> {current_prob:.3f} (å˜åŒ–: {change:+.3f})")
                        if change > 0.03:  # 3%é˜ˆå€¼
                            other_emotion_increased = True
                            print(f"   âœ… {emotion} ä¸Šå‡è¶…è¿‡3%: {change:.3f}")
                            break
                if not other_emotion_increased:
                    print(f"   âŒ æ²¡æœ‰å…¶ä»–æƒ…ç»ªä¸Šå‡è¶…è¿‡3%")
            else:
                print(f"   âš ï¸ æ²¡æœ‰ä¹‹å‰çš„å†å²æ¦‚ç‡æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨DialogueGCNç»“æœ")
            
            # åªæœ‰å½“æ²¡æœ‰å…¶ä»–æƒ…ç»ªä¸Šå‡3%æ—¶æ‰ä½¿ç”¨DialogueGCNç»“æœ
            if not other_emotion_increased:
                print(f"ğŸ¯ DialogueGCNéneutralç»“æœä¸”æ— å…¶ä»–æƒ…ç»ªä¸Šå‡: {gcn_emotion}")
                # æ›´æ–°å¯¹è¯å†å²
                if robot_text:
                    self.conversation_history.append((robot_text, 1))
                self.conversation_history.append((user_text, 0))
                
                # ä¿å­˜å½“å‰æ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
                self.previous_gcn_probs = gcn_probs.copy()
                
                return {
                    'emotion': gcn_emotion,
                    'confidence': gcn_result['confidence'],
                    'probabilities': gcn_probs,
                    'source': 'dialoguegcn_non_neutral_stable',
                    'reason': f"DialogueGCNé¢„æµ‹ä¸º{gcn_emotion}ä¸”æ— å…¶ä»–æƒ…ç»ªä¸Šå‡"
                }
            else:
                print(f"ğŸ”„ æ£€æµ‹åˆ°å…¶ä»–æƒ…ç»ªä¸Šå‡ï¼Œè°ƒç”¨å¤§æ¨¡å‹é‡æ–°åˆ¤æ–­...")
                context = " | ".join([f"{'æœºå™¨äºº' if speaker == 1 else 'ç”¨æˆ·'}: {text}" for text, speaker in self.conversation_history[-8:]])
                
                print(f"ğŸ“¤ å‘é€ç»™å¤§æ¨¡å‹çš„å†…å®¹:")
                print(f"   å½“å‰ç”¨æˆ·è¾“å…¥: {user_text}")
                print(f"   ä¸Šä¸‹æ–‡å†å²: {context if context else 'æ— '}")
                
                lm_result = self.large_model_client.analyze_emotion(user_text, context)
                
                print(f"ğŸ” å¤§æ¨¡å‹é‡æ–°åˆ¤æ–­ç»“æœ: {lm_result['emotion']} (ç½®ä¿¡åº¦: {lm_result['confidence']:.2%})")
                print(f" ğŸ” å¤§æ¨¡å‹åˆ¤æ–­åŸå› ï¼š{lm_result['reason']}")
                # æ›´æ–°å¯¹è¯å†å²
                if robot_text:
                    self.conversation_history.append((robot_text, 1))
                self.conversation_history.append((user_text, 0))
                
                # ä¿å­˜å½“å‰æ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
                self.previous_gcn_probs = gcn_probs.copy()
                
                return {
                    'emotion': lm_result['emotion'],
                    'confidence': lm_result['confidence'],
                    'probabilities': lm_result['emotion_probs'],
                    'source': 'large_model_other_emotion_rising',
                    'reason': f"æ£€æµ‹åˆ°å…¶ä»–æƒ…ç»ªä¸Šå‡ï¼Œå¤§æ¨¡å‹é‡æ–°åˆ¤æ–­ä¸º{lm_result['emotion']}"
                }
        
        # 3. ç»“æœä¸ºneutralï¼Œä½†æ˜¯|neutral-other|â‰¤5æ—¶ï¼Œè¿”å›ç¬¬äºŒé«˜çš„
        other_probs = {k: v for k, v in gcn_probs.items() if k != 'NEUTRAL'}
        if other_probs:
            max_other_prob = max(other_probs.values())
            max_other_emotion = max(other_probs, key=other_probs.get)
            
            if abs(neutral_prob - max_other_prob) <= 0.05:  # 5%é˜ˆå€¼
                print(f"ğŸ”„ neutralä¸å…¶ä»–æƒ…ç»ªæ¥è¿‘ï¼Œè¿”å›ç¬¬äºŒé«˜: {max_other_emotion}")
                # æ›´æ–°å¯¹è¯å†å²
                if robot_text:
                    self.conversation_history.append((robot_text, 1))
                self.conversation_history.append((user_text, 0))
                
                # ä¿å­˜å½“å‰æ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
                self.previous_gcn_probs = gcn_probs.copy()
                
                return {
                    'emotion': max_other_emotion,
                    'confidence': max_other_prob,
                    'probabilities': gcn_probs,
                    'source': 'dialoguegcn_second_highest',
                    'reason': f"neutralä¸{max_other_emotion}æ¥è¿‘ï¼Œé€‰æ‹©{max_other_emotion}"
                }
        
        # 4. |neutral-other|>5æ—¶ï¼Œå¦‚æœæŸä¸ªç½®ä¿¡åº¦å¢åŠ è¶…è¿‡2ï¼Œè°ƒç”¨å¤§æ¨¡å‹ï¼Œå¦åˆ™è¿˜æ˜¯è¾“å‡ºgcnåˆ¤æ–­ç»“æœ
        if abs(neutral_prob - max_other_prob) > 0.05:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç½®ä¿¡åº¦æ˜¾è‘—å¢åŠ 
            confidence_increased = False
            if self.previous_gcn_probs:
                print(f"ğŸ” æ£€æŸ¥ç½®ä¿¡åº¦å˜åŒ–:")
                print(f"   å½“å‰æ¦‚ç‡: {gcn_probs}")
                print(f"   ä¹‹å‰æ¦‚ç‡: {self.previous_gcn_probs}")
                for emotion in other_probs:
                    current_prob = gcn_probs.get(emotion, 0.0)
                    previous_prob = self.previous_gcn_probs.get(emotion, 0.0)
                    change = current_prob - previous_prob
                    print(f"   {emotion}: {previous_prob:.3f} -> {current_prob:.3f} (å˜åŒ–: {change:+.3f})")
                    if change > 0.02:  # 2%é˜ˆå€¼
                        confidence_increased = True
                        print(f"   âœ… {emotion} ç½®ä¿¡åº¦æ˜¾è‘—å¢åŠ  {change:.3f}")
                        break
                if not confidence_increased:
                    print(f"   âŒ æ²¡æœ‰æ£€æµ‹åˆ°ç½®ä¿¡åº¦æ˜¾è‘—å¢åŠ ")
            else:
                print(f"   âš ï¸ æ²¡æœ‰ä¹‹å‰çš„å†å²æ¦‚ç‡æ•°æ®")
            
            if confidence_increased:
                print("ğŸ”„ æ£€æµ‹åˆ°ç½®ä¿¡åº¦æ˜¾è‘—å¢åŠ ï¼Œè°ƒç”¨å¤§æ¨¡å‹é‡æ–°åˆ¤æ–­å½“å‰è½®...")
                context = " | ".join([f"{'æœºå™¨äºº' if speaker == 1 else 'ç”¨æˆ·'}: {text}" for text, speaker in self.conversation_history[-8:]])
                
                print(f"ğŸ“¤ å‘é€ç»™å¤§æ¨¡å‹çš„å†…å®¹:")
                print(f"   å½“å‰ç”¨æˆ·è¾“å…¥: {user_text}")
                print(f"   ä¸Šä¸‹æ–‡å†å²: {context if context else 'æ— '}")
                
                lm_result = self.large_model_client.analyze_emotion(user_text, context)
                
                print(f"ğŸ” å¤§æ¨¡å‹é‡æ–°åˆ¤æ–­ç»“æœ: {lm_result['emotion']} (ç½®ä¿¡åº¦: {lm_result['confidence']:.2%})")
                print(f" ğŸ” å¤§æ¨¡å‹åˆ¤æ–­åŸå› ï¼š{lm_result['reason']}")
                
                # 5. å¤§æ¨¡å‹åˆ¤æ–­ç»“æœåœ¨otherä¸Šå‡listå†…ï¼Œç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹ç»“æœï¼Œå¦åˆ™ä½¿ç”¨gcnå’Œå¤§æ¨¡å‹ç»¼åˆä¸‹æ¥çš„ç»“æœ
                lm_emotion = lm_result['emotion']
                if lm_emotion in other_probs:
                    print(f"ğŸ¯ å¤§æ¨¡å‹ç»“æœåœ¨ä¸Šå‡åˆ—è¡¨ä¸­: {lm_emotion}")
                    # 6. è°ƒç”¨å®Œå¤§æ¨¡å‹éœ€è¦é€‚å½“æ›´æ–°dialogueçš„ç½®ä¿¡åº¦
                    updated_gcn = self.update_gcn_confidence(gcn_result, lm_result)
                    
                    # æ›´æ–°å¯¹è¯å†å²
                    if robot_text:
                        self.conversation_history.append((robot_text, 1))
                    self.conversation_history.append((user_text, 0))
                    
                    # ä¿å­˜å½“å‰æ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
                    self.previous_gcn_probs = updated_gcn['probabilities'].copy()
                    
                    return {
                        'emotion': lm_emotion,
                        'confidence': lm_result['confidence'],
                        'probabilities': updated_gcn['probabilities'],
                        'source': 'large_model_in_rising_list',
                        'reason': f"å¤§æ¨¡å‹é‡æ–°åˆ¤æ–­{lm_emotion}ï¼Œåœ¨ä¸Šå‡åˆ—è¡¨ä¸­"
                    }
                else:
                    print(f"ğŸ”„ å¤§æ¨¡å‹ç»“æœä¸åœ¨ä¸Šå‡åˆ—è¡¨ä¸­ï¼Œç»¼åˆGCNå’Œå¤§æ¨¡å‹ç»“æœ")
                    # ç»¼åˆç»“æœ
                    combined_probs = {}
                    for emotion in gcn_probs:
                        gcn_prob = gcn_probs[emotion]
                        lm_prob = lm_result['emotion_probs'].get(emotion, 0.0)
                        combined_probs[emotion] = (gcn_prob + lm_prob) / 2.0
                    
                    max_emotion = max(combined_probs, key=combined_probs.get)
                    max_confidence = combined_probs[max_emotion]
                    
                    # æ›´æ–°å¯¹è¯å†å²
                    if robot_text:
                        self.conversation_history.append((robot_text, 1))
                    self.conversation_history.append((user_text, 0))
                    
                    # ä¿å­˜å½“å‰æ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
                    self.previous_gcn_probs = combined_probs.copy()
                    
                    return {
                        'emotion': max_emotion,
                        'confidence': max_confidence,
                        'probabilities': combined_probs,
                        'source': 'combined_gcn_lm',
                        'reason': f"å¤§æ¨¡å‹é‡æ–°åˆ¤æ–­åç»¼åˆDialogueGCNå’Œå¤§æ¨¡å‹ç»“æœ"
                    }
            else:
                print(f"ğŸ¯ ç½®ä¿¡åº¦æœªæ˜¾è‘—å¢åŠ ï¼Œä½¿ç”¨DialogueGCNç»“æœ: {gcn_emotion}")
                # æ›´æ–°å¯¹è¯å†å²
                if robot_text:
                    self.conversation_history.append((robot_text, 1))
                self.conversation_history.append((user_text, 0))
                
                return {
                    'emotion': gcn_emotion,
                    'confidence': gcn_result['confidence'],
                    'probabilities': gcn_probs,
                    'source': 'dialoguegcn_no_increase',
                    'reason': f"ç½®ä¿¡åº¦æœªæ˜¾è‘—å¢åŠ ï¼Œä½¿ç”¨DialogueGCNçš„{gcn_emotion}"
                }
        
        # æ›´æ–°å¯¹è¯å†å²
        if robot_text:
            self.conversation_history.append((robot_text, 1))
        self.conversation_history.append((user_text, 0))
        
        # ä¿æŒå†å²é•¿åº¦
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]
        
        # ä¿å­˜å½“å‰GCNæ¦‚ç‡ç”¨äºä¸‹æ¬¡æ¯”è¾ƒ
        self.previous_gcn_probs = gcn_probs.copy()
        
        return {
            'emotion': gcn_emotion,
            'confidence': gcn_result['confidence'],
            'probabilities': gcn_probs,
            'source': 'dialoguegcn_default',
            'reason': f"ä½¿ç”¨DialogueGCNé»˜è®¤ç»“æœ: {gcn_emotion}"
        }
    
    def run_pure_dgcn_interactive(self):
        """çº¯DialogueGCNäº¤äº’å¼è¯„ä¼°æ¨¡å¼
        
        åªä½¿ç”¨DialogueGCNè¿›è¡Œé¢„æµ‹ï¼Œä¸ä½¿ç”¨å¤§æ¨¡å‹æ··åˆç­–ç•¥
        ç”¨æˆ·å¯ä»¥äº¤äº’å¼è¾“å…¥æ–‡æœ¬ï¼Œç³»ç»Ÿè¿”å›DialogueGCNçš„é¢„æµ‹ç»“æœ
        """
        print("\n" + "="*60)
        print("ğŸ¯ çº¯DialogueGCNäº¤äº’å¼è¯„ä¼°")
        print("="*60)
        print("åªä½¿ç”¨DialogueGCNæ¨¡å‹è¿›è¡Œæƒ…ç»ªé¢„æµ‹")
        print("ä¸ä½¿ç”¨å¤§æ¨¡å‹æ··åˆç­–ç•¥")
        print("æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡")
        print("è¾“å…¥ 'quit' é€€å‡º")
        print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
        print("è¾“å…¥ 'stats' æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
        print("="*60)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_predictions = 0
        prediction_times = []
        emotion_counts = Counter()
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
                
                if user_input.lower() == 'quit':
                    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                    if total_predictions > 0:
                        print("\n" + "="*60)
                        print("ğŸ“Š ä¼šè¯ç»Ÿè®¡")
                        print("="*60)
                        print(f"æ€»é¢„æµ‹æ¬¡æ•°: {total_predictions}")
                        print(f"å¹³å‡è€—æ—¶: {np.mean(prediction_times):.2f}ms")
                        if len(prediction_times) > 1:
                            print(f"è€—æ—¶èŒƒå›´: {np.min(prediction_times):.2f}ms - {np.max(prediction_times):.2f}ms")
                        print(f"\næƒ…ç»ªåˆ†å¸ƒ:")
                        for emotion, count in emotion_counts.most_common():
                            print(f"  {emotion}: {count} ({count/total_predictions*100:.1f}%)")
                    print("\nğŸ‘‹ å†è§ï¼")
                    break
                    
                elif user_input.lower() == 'clear':
                    self.reset_dialogue_context()
                    print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")
                    continue
                    
                elif user_input.lower() == 'history':
                    print("\nğŸ“œ å¯¹è¯å†å²:")
                    if not self.conversation_history:
                        print("   æš‚æ— å¯¹è¯å†å²")
                    else:
                        for i, (text, speaker) in enumerate(self.conversation_history[-10:]):
                            speaker_name = "ç”¨æˆ·" if speaker == 0 else "æœºå™¨äºº"
                            print(f"   {i+1}. {speaker_name}: {text}")
                    continue
                    
                elif user_input.lower() == 'stats':
                    print("\nğŸ“Š å½“å‰ç»Ÿè®¡:")
                    print(f"æ€»é¢„æµ‹æ¬¡æ•°: {total_predictions}")
                    if prediction_times:
                        print(f"å¹³å‡è€—æ—¶: {np.mean(prediction_times):.2f}ms")
                        print(f"æœ€å¿«/æœ€æ…¢: {np.min(prediction_times):.2f}ms / {np.max(prediction_times):.2f}ms")
                    print(f"å¯¹è¯å†å²é•¿åº¦: {len(self.conversation_history)}")
                    if emotion_counts:
                        print(f"æƒ…ç»ªåˆ†å¸ƒ:")
                        for emotion, count in emotion_counts.most_common():
                            print(f"  {emotion}: {count} ({count/total_predictions*100:.1f}%)")
                    continue
                    
                elif not user_input:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                    continue
                
                # ä½¿ç”¨çº¯DialogueGCNé¢„æµ‹
                print("\nğŸ” æ­£åœ¨ä½¿ç”¨DialogueGCNåˆ†ææƒ…ç»ª...")
                t0 = time.perf_counter()
                gcn_result = self.get_dialoguegcn_prediction(user_input, robot_text="")
                elapsed_ms = (time.perf_counter() - t0) * 1000.0
                
                if gcn_result:
                    emotion = gcn_result['emotion']
                    confidence = gcn_result['confidence']
                    probabilities = gcn_result['probabilities']
                    
                    # æ›´æ–°ç»Ÿè®¡
                    total_predictions += 1
                    prediction_times.append(elapsed_ms)
                    emotion_counts[emotion] += 1
                    
                    # æ˜¾ç¤ºç»“æœ
                    print(f"\nğŸ“Š DialogueGCNé¢„æµ‹ç»“æœ:")
                    print(f"   é¢„æµ‹æƒ…ç»ª: {emotion} (ç½®ä¿¡åº¦: {confidence:.2%})")
                    print(f"   é¢„æµ‹è€—æ—¶: {elapsed_ms:.2f}ms")
                    print(f"   æ‰€æœ‰æƒ…ç»ªæ¦‚ç‡:")
                    for emo, prob in sorted(probabilities.items(), key=lambda x: x[1], reverse=True):
                        bar = "â–ˆ" * int(prob * 20)
                        print(f"     {emo:8}: {prob:.2%} {bar}")
                    
                    # æ›´æ–°å¯¹è¯å†å²
                    self.conversation_history.append((user_input, 0))
                    
                else:
                    print("âŒ DialogueGCNé¢„æµ‹å¤±è´¥")
                    continue
                
                # å¯é€‰çš„æœºå™¨äººå›å¤
                robot_input = input("\nğŸ¤– æœºå™¨äººå›å¤ (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
                if robot_input:
                    self.conversation_history.append((robot_input, 1))
                    print(f"âœ… æœºå™¨äººå›å¤å·²è®°å½•")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
    
    def run_demo(self):
        """è¿è¡Œäº¤äº’å¼demo"""
        print("\n" + "="*60)
        print("ğŸ­ æœ€ç»ˆæ··åˆæƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ")
        print("="*60)
        print("ç»“åˆDialogueGCNå’Œå¤§æ¨¡å‹çš„æ™ºèƒ½æƒ…ç»ªåˆ¤æ–­")
        print("æ”¯æŒå¤šè½®å¯¹è¯ï¼Œæ™ºèƒ½ç®—æ³•å†³ç­–")
        print("è¾“å…¥ 'quit' é€€å‡ºç¨‹åº")
        print("è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("è¾“å…¥ 'reset' é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆç­‰åŒäºclearï¼‰")
        print("è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
        print("è¾“å…¥ 'test' è¿è¡Œæµ‹è¯•ç”¨ä¾‹ï¼ˆæ··åˆç­–ç•¥ï¼‰")
        print("è¾“å…¥ 'test_lm' ä»…å¤§æ¨¡å‹å•è½®è¯„ä¼°(æ— ä¸Šä¸‹æ–‡)")
        print("è¾“å…¥ 'test_dgcn' çº¯DialogueGCNæµ‹è¯•(æ–‡ä»¶è¯„ä¼°)")
        print("è¾“å…¥ 'interactive_dgcn' çº¯DialogueGCNäº¤äº’å¼è¯„ä¼°")
        print("="*60)
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ‘¤ ç”¨æˆ·: ").strip()
                
                if user_input.lower() == 'quit':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                elif user_input.lower() == 'clear':
                    self.reset_dialogue_context()
                    print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")
                    continue
                elif user_input.lower() == 'reset':
                    self.reset_dialogue_context()
                    print("ğŸ”„ å¯¹è¯ä¸Šä¸‹æ–‡å·²é‡ç½®")
                    continue
                elif user_input.lower() == 'history':
                    print("\nğŸ“œ å¯¹è¯å†å²:")
                    if not self.conversation_history:
                        print("   æš‚æ— å¯¹è¯å†å²")
                    else:
                        for i, (text, speaker) in enumerate(self.conversation_history[-5:]):
                            speaker_name = "ç”¨æˆ·" if speaker == 0 else "æœºå™¨äºº"
                            print(f"   {i+1}. {speaker_name}: {text}")
                    continue
                elif user_input.lower() == 'test':
                    self.run_test_cases()
                    continue
                elif user_input.lower() == 'test_lm':
                    self.run_large_model_single_turn_test()
                    continue
                elif user_input.lower() == 'test_dgcn':
                    self.run_pure_dialoguegcn_test()
                    continue
                elif user_input.lower() == 'interactive_dgcn':
                    self.run_pure_dgcn_interactive()
                    continue
                elif not user_input:
                    print("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹")
                    continue
                
                # åœ¨ç”¨æˆ·è¾“å…¥åç«‹å³é¢„æµ‹æƒ…ç»ª
                print("\nğŸ” æ­£åœ¨åˆ†æç”¨æˆ·æƒ…ç»ª...")
                result = self.predict_emotion(user_input)
                
                if result:
                    print(f"\nğŸ“Š æƒ…ç»ªåˆ†æç»“æœ:")
                    print(f"   é¢„æµ‹æƒ…ç»ª: {result['emotion']} (ç½®ä¿¡åº¦: {result['confidence']:.2%})")
                    print(f"   åˆ¤æ–­æ¥æº: {result['source']}")
                    print(f"   åˆ¤æ–­ä¾æ®: {result['reason']}")
                    print(f"   æ‰€æœ‰æƒ…ç»ªæ¦‚ç‡:")
                    for emotion, prob in result['probabilities'].items():
                        bar = "â–ˆ" * int(prob * 20)
                        print(f"     {emotion:8}: {prob:.2%} {bar}")
                else:
                    print("âŒ æƒ…ç»ªåˆ†æå¤±è´¥")
                
                # è·å–æœºå™¨äººå›å¤ï¼ˆå¯é€‰ï¼‰
                robot_input = input("\nğŸ¤– æœºå™¨äºº: ").strip()
                if robot_input:
                    # å¦‚æœæœ‰æœºå™¨äººå›å¤ï¼Œæ›´æ–°å¯¹è¯å†å²
                    self.conversation_history.append((robot_input, 1))
                    print(f"âœ… æœºå™¨äººå›å¤å·²è®°å½•: {robot_input}")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
    
    def run_test_cases(self, data_path: str = 'improved_test_data.xlsx'):
        """åŸºäºtest_data.xlsxè¿è¡Œè¯„ä¼°ï¼Œç”¨æ•°æ®æ–‡ä»¶ä¸­çš„æ ‡ç­¾å¯¹æ¯”é¢„æµ‹ç»“æœã€‚

        è¦æ±‚ï¼š
        - æ•°æ®åˆ—åŒ…å«: dialogue_id, speaker(user/robot), utterance, emotion_label
        - åªæœ‰speakerä¸ºuseræ—¶æ‰æœ‰emotion_label
        - æ¯æ®µå¯¹è¯éƒ½æ˜¯æœºå™¨äººå…ˆè¯´ï¼šéœ€å°†æœºå™¨äººè½®ä½œä¸ºå†å²å†™å…¥ï¼Œä¸è§¦å‘é¢„æµ‹
        - å¯¹æ¯æ¡ç”¨æˆ·(æœ‰æ ‡ç­¾)æ•°æ®è¾“å‡ºï¼šutteranceã€è€—æ—¶ã€é¢„æµ‹ä¸å®é™…æƒ…ç»ªæ ‡ç­¾
        - æœ€ç»ˆè¾“å‡ºï¼šæ€»ä½“å‡†ç¡®ç‡ã€å„ç±»æƒ…ç»ªå¬å›ç‡ã€å¹³å‡è€—æ—¶ã€è€—æ—¶5/50/95åˆ†ä½
        - é¢å¤–ç»Ÿè®¡ï¼šå½“æœ€ç»ˆç»“æœæ¥è‡ªDialogueGCNæ—¶çš„å‡†ç¡®ç‡
        """
        # å°è¯•å¯¼å…¥sklearnä»¥ä¾¿è®¡ç®—å¬å›ç‡ï¼Œä¸å¯ç”¨åˆ™å›é€€åˆ°æ‰‹å·¥è®¡ç®—
        try:
            from sklearn.metrics import precision_recall_fscore_support
            _SK_AVAILABLE = True
        except Exception:
            _SK_AVAILABLE = False

        if not os.path.exists(data_path):
            print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {data_path}")
            return

        try:
            if data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
            elif data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ.xlsxæˆ–.csv")
                return
        except Exception as e:
            print(f"âŒ è¯»å–æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return

        required_cols = {'dialogue_id', 'speaker', 'utterance', 'emotion_label'}
        if not required_cols.issubset(set(df.columns)):
            print(f"âŒ æµ‹è¯•æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œéœ€åŒ…å«: {sorted(required_cols)}ï¼Œå½“å‰: {list(df.columns)}")
            return

        # æ ‡å‡†åŒ–åˆ—ç±»å‹
        df = df.copy()
        df['speaker'] = df['speaker'].astype(str)
        df['dialogue_id'] = df['dialogue_id']

        # ç»Ÿè®¡ä¿¡æ¯
        user_rows = df[(df['speaker'] == 'user') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        print("\nğŸ§ª åŸºäºæ–‡ä»¶è¿›è¡Œè¯„ä¼°...")
        print(f"æ€»è®°å½•æ•°: {len(df)} | ç”¨æˆ·(æœ‰æ ‡ç­¾)è®°å½•æ•°: {len(user_rows)}")

        label_map = {
            'neutral': 'NEUTRAL',
            'happy': 'HAPPY',
            'sad': 'SAD',
            'angry': 'ANGRY',
            'surprise': 'SURPRISE'
        }
        valid_labels = ['NEUTRAL', 'ANGRY', 'SAD', 'HAPPY', 'SURPRISE']

        y_true, y_pred, times = [], [], []
        # é¢å¤–ç»Ÿè®¡ï¼šè®°å½•æ¯æ¬¡é¢„æµ‹çš„æ¥æº
        sources = []

        # æŒ‰å¯¹è¯åˆ†ç»„ï¼šæ¯æ®µå¯¹è¯é‡ç½®å†…éƒ¨çŠ¶æ€ï¼Œå¤ç”¨åŒä¸€æ¨¡å‹
        for dialogue_id, group in df.groupby('dialogue_id', sort=False):
            print(f"\n=== å¯¹è¯ {dialogue_id} å¼€å§‹ï¼Œ{len(group)} æ¡ ===")
            # é‡ç½®å†…éƒ¨çŠ¶æ€ï¼Œä¿æŒæ¨¡å‹ä¸å˜
            self.reset_dialogue_context()

            group = group.reset_index(drop=True)
            for idx, row in group.iterrows():
                speaker = str(row['speaker']).strip().lower()
                utterance = str(row['utterance']) if not pd.isna(row['utterance']) else ''
                true_label_raw = row.get('emotion_label')
                true_label = '' if pd.isna(true_label_raw) else str(true_label_raw)

                if speaker == 'robot':
                    # æœºå™¨äººè½®ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æƒ…ç»ªæ ‡ç­¾ï¼Œå¦‚æœæœ‰åˆ™è¿›è¡Œé¢„æµ‹
                    if utterance.strip():
                        self.conversation_history.append((utterance.strip(), 1))
                    
                    # å¦‚æœrobotæœ‰æƒ…ç»ªæ ‡ç­¾ï¼Œä¹Ÿè¿›è¡Œé¢„æµ‹
                    if true_label.strip():
                        t0 = time.perf_counter()
                        result = self.predict_emotion(utterance, robot_text="", dialogue_id=dialogue_id)
                        elapsed_ms = (time.perf_counter() - t0) * 1000.0

                        pred = (result.get('emotion') or '').upper()
                        source = result.get('source', 'unknown')
                        mapped_true = label_map.get(true_label.lower(), true_label.upper())
                        y_true.append(mapped_true)
                        y_pred.append(pred)
                        times.append(elapsed_ms)
                        sources.append(source)

                        print(f"Robotè¯è¯­: {utterance}")
                        print(f"è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} | å®é™…: {mapped_true} | æ¥æº: {source}")
                    continue

                if speaker == 'user':
                    # ç”¨æˆ·è½®ï¼šè‹¥æ— æ ‡ç­¾ï¼Œåˆ™ä»…ä½œä¸ºå†å²ï¼›æœ‰æ ‡ç­¾åˆ™è¿›è¡Œé¢„æµ‹æ¯”å¯¹
                    if not true_label.strip():
                        if utterance.strip():
                            self.conversation_history.append((utterance.strip(), 0))
                        continue

                    # æœ‰æ ‡ç­¾ç”¨æˆ·è½®ï¼šæ‰§è¡Œé¢„æµ‹
                    t0 = time.perf_counter()
                    result = self.predict_emotion(utterance, robot_text="", dialogue_id=dialogue_id)
                    elapsed_ms = (time.perf_counter() - t0) * 1000.0

                    pred = (result.get('emotion') or '').upper()
                    source = result.get('source', 'unknown')
                    mapped_true = label_map.get(true_label.lower(), true_label.upper())
                    y_true.append(mapped_true)
                    y_pred.append(pred)
                    times.append(elapsed_ms)
                    sources.append(source)

                    print(f"Userè¯è¯­: {utterance}")
                    print(f"è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} | å®é™…: {mapped_true} | æ¥æº: {source}")

        # æ±‡æ€»æŒ‡æ ‡
        if not y_true:
            print("\nâŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ ‡æ³¨æ•°æ®ï¼ˆç”¨æˆ·æˆ–æœºå™¨äººï¼‰")
            return

        y_true_np = np.array(y_true)
        y_pred_np = np.array(y_pred)
        accuracy = float((y_true_np == y_pred_np).mean())

        print("\nâ€”â€” æŒ‡æ ‡æ±‡æ€» â€”â€”")
        print(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")

        # å„ç±»å¬å›ç‡
        print("å„ç±»æƒ…ç»ªå¬å›ç‡:")
        if _SK_AVAILABLE:
            try:
                _, recall, _, support = precision_recall_fscore_support(
                    y_true_np, y_pred_np, labels=valid_labels, zero_division=0
                )
                for lbl, r, sup in zip(valid_labels, recall, support):
                    print(f"  {lbl:<9} Recall {r:.4f} (support={int(sup)})")
            except Exception as e:
                print(f"  è®¡ç®—å¬å›ç‡å¤±è´¥: {e}")
        else:
            # æ‰‹å·¥è®¡ç®—å¬å›ç‡
            for lbl in valid_labels:
                sup = int((y_true_np == lbl).sum())
                tp = int(((y_true_np == lbl) & (y_pred_np == lbl)).sum())
                rec = tp / sup if sup > 0 else 0.0
                print(f"  {lbl:<9} Recall {rec:.4f} (support={sup})")

        # è€—æ—¶ç»Ÿè®¡
        t = np.array(times, dtype=float)
        if t.size > 0:
            print("è€—æ—¶ç»Ÿè®¡:")
            print(f"  å¹³å‡è€—æ—¶: {t.mean():.2f}ms")
            print(f"  5åˆ†ä½: {np.percentile(t, 5):.2f}ms | 50åˆ†ä½: {np.percentile(t, 50):.2f}ms | 95åˆ†ä½: {np.percentile(t, 95):.2f}ms")
        else:
            print("è€—æ—¶ç»Ÿè®¡: æ— ")
        
        # ç»Ÿè®¡DialogueGCNç»“æœçš„å‡†ç¡®ç‡
        print("\nâ€”â€” DialogueGCNç»“æœå‡†ç¡®ç‡ â€”â€”")
        # æ‰¾å‡ºæ‰€æœ‰æ¥è‡ªDialogueGCNçš„é¢„æµ‹
        dgcn_sources = ['dialoguegcn_non_neutral_stable', 'dialoguegcn_second_highest', 
                        'dialoguegcn_no_increase', 'dialoguegcn_default', 'dialoguegcn']
        dgcn_mask = np.array([s in dgcn_sources for s in sources])
        if dgcn_mask.sum() > 0:
            dgcn_y_true = y_true_np[dgcn_mask]
            dgcn_y_pred = y_pred_np[dgcn_mask]
            dgcn_accuracy = float((dgcn_y_true == dgcn_y_pred).mean())
            print(f"DialogueGCNç»“æœæ•°é‡: {dgcn_mask.sum()} / {len(sources)} ({dgcn_mask.sum()/len(sources)*100:.1f}%)")
            print(f"DialogueGCNç»“æœå‡†ç¡®ç‡: {dgcn_accuracy:.4f} ({dgcn_accuracy*100:.2f}%)")
        else:
            print("æ— DialogueGCNç»“æœ")

    def run_large_model_single_turn_test(self, data_path: str = 'improved_test_data.xlsx'):
        """ä»…è°ƒç”¨å¤§æ¨¡å‹ï¼ˆæ— ä¸Šä¸‹æ–‡ï¼‰å¯¹ç”¨æˆ·æ ‡æ³¨æ•°æ®è¿›è¡Œå•è½®è¯„ä¼°ã€‚

        - ä¸ä½¿ç”¨å¯¹è¯å†å²ä¸GCNï¼Œä»…å¯¹æ¯æ¡ç”¨æˆ·(æœ‰æ ‡ç­¾)è¯è¯­å•ç‹¬è°ƒç”¨å¤§æ¨¡å‹ã€‚
        - è¾“å‡ºé€æ¡ç»“æœï¼ˆè¯è¯­ã€è€—æ—¶ã€é¢„æµ‹ã€å®é™…ï¼‰ï¼Œå¹¶ç»Ÿè®¡å‡†ç¡®ç‡ã€å„ç±»å¬å›ç‡ã€å¹³å‡è€—æ—¶ã€5/95åˆ†ä½ã€‚
        """
        # sklearn å¯é€‰
        try:
            from sklearn.metrics import precision_recall_fscore_support
            _SK_AVAILABLE = True
        except Exception:
            _SK_AVAILABLE = False

        if not os.path.exists(data_path):
            print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {data_path}")
            return

        try:
            if data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
            elif data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ.xlsxæˆ–.csv")
                return
        except Exception as e:
            print(f"âŒ è¯»å–æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return

        required_cols = {'dialogue_id', 'speaker', 'utterance', 'emotion_label'}
        if not required_cols.issubset(set(df.columns)):
            print(f"âŒ æµ‹è¯•æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œéœ€åŒ…å«: {sorted(required_cols)}ï¼Œå½“å‰: {list(df.columns)}")
            return

        # ä»…å–ç”¨æˆ·ä¸”æœ‰æ ‡ç­¾çš„æ•°æ®
        user_df = df[(df['speaker'] == 'user') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')].copy()
        if user_df.empty:
            print("âŒ æ— ç”¨æˆ·æ ‡æ³¨æ•°æ®å¯è¯„ä¼°")
            return

        print("\nğŸ§ª ä»…å¤§æ¨¡å‹å•è½®è¯„ä¼°(æ— ä¸Šä¸‹æ–‡)...")
        print(f"æ ·æœ¬æ•°: {len(user_df)}")

        label_map = {
            'neutral': 'NEUTRAL',
            'happy': 'HAPPY',
            'sad': 'SAD',
            'angry': 'ANGRY',
            'surprise': 'SURPRISE'
        }
        valid_labels = ['NEUTRAL', 'ANGRY', 'SAD', 'HAPPY', 'SURPRISE']

        y_true, y_pred, times = [], [], []
        for _, row in user_df.reset_index(drop=True).iterrows():
            utterance = '' if pd.isna(row['utterance']) else str(row['utterance'])
            true_raw = row['emotion_label']
            true_label = label_map.get(str(true_raw).lower(), str(true_raw).upper())

            # è°ƒç”¨å¤§æ¨¡å‹ï¼ˆæ— ä¸Šä¸‹æ–‡ï¼‰
            t0 = time.perf_counter()
            lm_result = self.large_model_client.analyze_emotion(utterance, context="")
            elapsed_ms_outer = (time.perf_counter() - t0) * 1000.0
            pred_label = (lm_result.get('emotion') or '').upper()
            elapsed_ms = float(lm_result.get('response_time_ms', elapsed_ms_outer))

            y_true.append(true_label)
            y_pred.append(pred_label)
            times.append(elapsed_ms)

            print(f"è¯è¯­: {utterance}")
            print(f"è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred_label} | å®é™…: {true_label}")

        # æ±‡æ€»
        y_true_np = np.array(y_true)
        y_pred_np = np.array(y_pred)
        accuracy = float((y_true_np == y_pred_np).mean())

        print("\nâ€”â€” æŒ‡æ ‡æ±‡æ€»ï¼ˆå¤§æ¨¡å‹å•è½®ï¼‰â€”â€”")
        print(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")

        print("å„ç±»æƒ…ç»ªå¬å›ç‡:")
        if _SK_AVAILABLE:
            try:
                _, recall, _, support = precision_recall_fscore_support(
                    y_true_np, y_pred_np, labels=valid_labels, zero_division=0
                )
                for lbl, r, sup in zip(valid_labels, recall, support):
                    print(f"  {lbl:<9} Recall {r:.4f} (support={int(sup)})")
            except Exception as e:
                print(f"  è®¡ç®—å¬å›ç‡å¤±è´¥: {e}")
        else:
            for lbl in valid_labels:
                sup = int((y_true_np == lbl).sum())
                tp = int(((y_true_np == lbl) & (y_pred_np == lbl)).sum())
                rec = tp / sup if sup > 0 else 0.0
                print(f"  {lbl:<9} Recall {rec:.4f} (support={sup})")

        t = np.array(times, dtype=float)
        if t.size > 0:
            print("è€—æ—¶ç»Ÿè®¡:")
            print(f"  å¹³å‡è€—æ—¶: {t.mean():.2f}ms")
            print(f"  5åˆ†ä½: {np.percentile(t, 5):.2f}ms | 50åˆ†ä½: {np.percentile(t, 50):.2f}ms | 95åˆ†ä½: {np.percentile(t, 95):.2f}ms")
        else:
            print("è€—æ—¶ç»Ÿè®¡: æ— ")
    
    def run_pure_dialoguegcn_test(self, data_path: str = 'improved_test_data.xlsx'):
        """çº¯DialogueGCNæµ‹è¯•ï¼ˆä¸ä½¿ç”¨å¤§æ¨¡å‹æ··åˆç­–ç•¥ï¼‰
        
        - å¯¹æ¯æ¡ç”¨æˆ·è¯è¯­ä»…ä½¿ç”¨DialogueGCNè¿›è¡Œé¢„æµ‹
        - è¾“å‡ºå‡†ç¡®ç‡ã€å„ç±»å¬å›ç‡ã€è€—æ—¶ç»Ÿè®¡ï¼ˆåŒ…æ‹¬50åˆ†ä½ï¼‰
        """
        try:
            from sklearn.metrics import precision_recall_fscore_support
            _SK_AVAILABLE = True
        except Exception:
            _SK_AVAILABLE = False

        if not os.path.exists(data_path):
            print(f"âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {data_path}")
            return

        try:
            if data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
            elif data_path.endswith('.csv'):
                df = pd.read_csv(data_path)
            else:
                print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒ.xlsxæˆ–.csv")
                return
        except Exception as e:
            print(f"âŒ è¯»å–æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            return

        required_cols = {'dialogue_id', 'speaker', 'utterance', 'emotion_label'}
        if not required_cols.issubset(set(df.columns)):
            print(f"âŒ æµ‹è¯•æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œéœ€åŒ…å«: {sorted(required_cols)}ï¼Œå½“å‰: {list(df.columns)}")
            return

        df = df.copy()
        df['speaker'] = df['speaker'].astype(str)
        df['dialogue_id'] = df['dialogue_id']

        user_rows = df[(df['speaker'] == 'user') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        robot_rows = df[(df['speaker'] == 'robot') & df['emotion_label'].notna() & (df['emotion_label'].astype(str) != '')]
        print("\nğŸ§ª çº¯DialogueGCNæµ‹è¯•ï¼ˆä¸ä½¿ç”¨æ··åˆç­–ç•¥ï¼‰...")
        print(f"æ€»è®°å½•æ•°: {len(df)} | ç”¨æˆ·(æœ‰æ ‡ç­¾)è®°å½•æ•°: {len(user_rows)} | æœºå™¨äºº(æœ‰æ ‡ç­¾)è®°å½•æ•°: {len(robot_rows)}")

        label_map = {
            'neutral': 'NEUTRAL',
            'happy': 'HAPPY',
            'sad': 'SAD',
            'angry': 'ANGRY',
            'surprise': 'SURPRISE'
        }
        valid_labels = ['NEUTRAL', 'ANGRY', 'SAD', 'HAPPY', 'SURPRISE']

        y_true, y_pred, times = [], [], []

        # æŒ‰å¯¹è¯åˆ†ç»„
        for dialogue_id, group in df.groupby('dialogue_id', sort=False):
            print(f"\n=== å¯¹è¯ {dialogue_id} å¼€å§‹ï¼Œ{len(group)} æ¡ ===")
            # é‡ç½®å†…éƒ¨çŠ¶æ€
            self.reset_dialogue_context()

            group = group.reset_index(drop=True)
            for idx, row in group.iterrows():
                speaker = str(row['speaker']).strip().lower()
                utterance = str(row['utterance']) if not pd.isna(row['utterance']) else ''
                true_label_raw = row.get('emotion_label')
                true_label = '' if pd.isna(true_label_raw) else str(true_label_raw)

                if speaker == 'robot':
                    if utterance.strip():
                        self.conversation_history.append((utterance.strip(), 1))
                    
                    # å¦‚æœrobotæœ‰æƒ…ç»ªæ ‡ç­¾ï¼Œä¹Ÿè¿›è¡Œé¢„æµ‹
                    if true_label.strip():
                        t0 = time.perf_counter()
                        gcn_result = self.get_dialoguegcn_prediction(utterance, robot_text="")
                        elapsed_ms = (time.perf_counter() - t0) * 1000.0

                        if gcn_result:
                            pred = gcn_result['emotion']
                        else:
                            pred = 'NEUTRAL'  # å¤±è´¥æ—¶é»˜è®¤NEUTRAL
                            print(f"âš ï¸ DialogueGCNé¢„æµ‹å¤±è´¥ï¼Œé»˜è®¤ä¸ºNEUTRAL")

                        mapped_true = label_map.get(true_label.lower(), true_label.upper())
                        y_true.append(mapped_true)
                        y_pred.append(pred)
                        times.append(elapsed_ms)

                        print(f"Robotè¯è¯­: {utterance}")
                        print(f"è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} | å®é™…: {mapped_true}")
                    continue

                if speaker == 'user':
                    if not true_label.strip():
                        if utterance.strip():
                            self.conversation_history.append((utterance.strip(), 0))
                        continue

                    # æœ‰æ ‡ç­¾ç”¨æˆ·è½®ï¼šä»…ä½¿ç”¨DialogueGCNé¢„æµ‹
                    t0 = time.perf_counter()
                    gcn_result = self.get_dialoguegcn_prediction(utterance, robot_text="")
                    elapsed_ms = (time.perf_counter() - t0) * 1000.0

                    if gcn_result:
                        pred = gcn_result['emotion']
                        # æ›´æ–°å¯¹è¯å†å²
                        self.conversation_history.append((utterance.strip(), 0))
                    else:
                        pred = 'NEUTRAL'  # å¤±è´¥æ—¶é»˜è®¤NEUTRAL
                        print(f"âš ï¸ DialogueGCNé¢„æµ‹å¤±è´¥ï¼Œé»˜è®¤ä¸ºNEUTRAL")

                    mapped_true = label_map.get(true_label.lower(), true_label.upper())
                    y_true.append(mapped_true)
                    y_pred.append(pred)
                    times.append(elapsed_ms)

                    print(f"Userè¯è¯­: {utterance}")
                    print(f"è€—æ—¶: {elapsed_ms:.1f}ms | é¢„æµ‹: {pred} | å®é™…: {mapped_true}")

        # æ±‡æ€»æŒ‡æ ‡
        if not y_true:
            print("\nâŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ ‡æ³¨æ•°æ®ï¼ˆç”¨æˆ·æˆ–æœºå™¨äººï¼‰")
            return

        y_true_np = np.array(y_true)
        y_pred_np = np.array(y_pred)
        accuracy = float((y_true_np == y_pred_np).mean())

        print("\nâ€”â€” çº¯DialogueGCNæŒ‡æ ‡æ±‡æ€» â€”â€”")
        print(f"æ€»ä½“å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")

        # å„ç±»å¬å›ç‡
        print("å„ç±»æƒ…ç»ªå¬å›ç‡:")
        if _SK_AVAILABLE:
            try:
                _, recall, _, support = precision_recall_fscore_support(
                    y_true_np, y_pred_np, labels=valid_labels, zero_division=0
                )
                for lbl, r, sup in zip(valid_labels, recall, support):
                    print(f"  {lbl:<9} Recall {r:.4f} (support={int(sup)})")
            except Exception as e:
                print(f"  è®¡ç®—å¬å›ç‡å¤±è´¥: {e}")
        else:
            for lbl in valid_labels:
                sup = int((y_true_np == lbl).sum())
                tp = int(((y_true_np == lbl) & (y_pred_np == lbl)).sum())
                rec = tp / sup if sup > 0 else 0.0
                print(f"  {lbl:<9} Recall {rec:.4f} (support={sup})")

        # è€—æ—¶ç»Ÿè®¡
        t = np.array(times, dtype=float)
        if t.size > 0:
            print("è€—æ—¶ç»Ÿè®¡:")
            print(f"  å¹³å‡è€—æ—¶: {t.mean():.2f}ms")
            print(f"  5åˆ†ä½: {np.percentile(t, 5):.2f}ms | 50åˆ†ä½: {np.percentile(t, 50):.2f}ms | 95åˆ†ä½: {np.percentile(t, 95):.2f}ms")
        else:
            print("è€—æ—¶ç»Ÿè®¡: æ— ")

def main():
    """ä¸»å‡½æ•°"""
    # æŸ¥æ‰¾å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶
    model_files = []
    for file in os.listdir('.'):
        if file.startswith('chinese_dialoguegcn_model_epoch_') and file.endswith('.pth'):
            model_files.append(file)
    
    if not model_files:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹æ–‡ä»¶")
        return
    
    # é€‰æ‹©æœ€æ–°çš„æ¨¡å‹
    latest_model = sorted(model_files)[-1]
    print(f"ğŸ“ æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {latest_model}")
    
    # æ£€æŸ¥è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = FinalEmotionSystem(latest_model, device)
    
    if system.model is None:
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        return
    
    # è¿è¡Œäº¤äº’å¼demo
    system.run_demo()

if __name__ == "__main__":
    main()
 