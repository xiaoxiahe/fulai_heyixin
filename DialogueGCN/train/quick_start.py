#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­æ–‡å¤šè½®å¯¹è¯æƒ…ç»ªè¯†åˆ«å¿«é€Ÿå¯åŠ¨è„šæœ¬
ä¸€é”®å®Œæˆæ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹è®­ç»ƒ
"""

import os
import sys
import subprocess
import argparse
import time
from pathlib import Path

def run_command(cmd, description):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print(f"\n{'='*50}")
    print(f"æ­£åœ¨æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {cmd}")
    print(f"{'='*50}")
    
    start_time = time.time()
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    end_time = time.time()
    
    if result.returncode == 0:
        print(f"âœ… {description} å®Œæˆ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
        if result.stdout:
            print("è¾“å‡º:")
            print(result.stdout)
    else:
        print(f"âŒ {description} å¤±è´¥")
        print("é”™è¯¯ä¿¡æ¯:")
        print(result.stderr)
        return False
    
    return True

def check_file_exists(file_path, description):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯: {description} ä¸å­˜åœ¨: {file_path}")
        return False
    print(f"âœ… {description} å­˜åœ¨: {file_path}")
    return True

def main():
    parser = argparse.ArgumentParser(description='ä¸­æ–‡å¤šè½®å¯¹è¯æƒ…ç»ªè¯†åˆ«å¿«é€Ÿå¯åŠ¨')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--input', required=True, help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--output', default='chinese_data.pkl', help='è¾“å‡ºpklæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model', default='LSTM', choices=['LSTM', 'GRU', 'DialogRNN'], help='åŸºç¡€æ¨¡å‹')
    parser.add_argument('--use_graph', action='store_true', help='ä½¿ç”¨å›¾ç¥ç»ç½‘ç»œ')
    parser.add_argument('--use_bert', action='store_true', help='ä½¿ç”¨BERTç‰¹å¾æå–')
    parser.add_argument('--epochs', type=int, default=60, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--output_dir', default='./saved/chinese/', help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--skip_preprocess', action='store_true', help='è·³è¿‡æ•°æ®é¢„å¤„ç†æ­¥éª¤')
    parser.add_argument('--skip_analysis', action='store_true', help='è·³è¿‡æ•°æ®åˆ†ææ­¥éª¤')
    
    args = parser.parse_args()
    
    print("ğŸš€ ä¸­æ–‡å¤šè½®å¯¹è¯æƒ…ç»ªè¯†åˆ«å¿«é€Ÿå¯åŠ¨")
    print("="*60)
    print(f"è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    print(f"åŸºç¡€æ¨¡å‹: {args.model}")
    print(f"ä½¿ç”¨å›¾ç¥ç»ç½‘ç»œ: {args.use_graph}")
    print(f"ä½¿ç”¨BERT: {args.use_bert}")
    print(f"è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"æ‰¹å¤„ç†å¤§å°: {args.batch_size}")
    print("="*60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not check_file_exists(args.input, "è¾“å…¥CSVæ–‡ä»¶"):
        return
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    required_files = [
        'preprocess_chinese_data.py',
        'emotion_mapping.py', 
        'train_chinese.py',
        'chinese_dataloader.py',
        'model.py'
    ]
    
    for file in required_files:
        if not check_file_exists(file, f"å¿…è¦æ–‡ä»¶ {file}"):
            print(f"è¯·ç¡®ä¿æ‰€æœ‰å¿…è¦æ–‡ä»¶éƒ½åœ¨å½“å‰ç›®å½•ä¸‹")
            return
    
    # æ­¥éª¤1: æ•°æ®åˆ†æ (å¯é€‰)
    if not args.skip_analysis:
        cmd = f"python emotion_mapping.py --input {args.input} --emotion_col Emotion --analyze --weights"
        if not run_command(cmd, "æ•°æ®åˆ†æ"):
            print("âš ï¸ æ•°æ®åˆ†æå¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­")
    
    # æ­¥éª¤2: æ•°æ®é¢„å¤„ç† (å¯é€‰)
    if not args.skip_preprocess:
        cmd = f"python preprocess_chinese_data.py --input {args.input} --output {args.output}"
        if args.use_bert:
            cmd += " --bert_model hfl/chinese-roberta-wwm-ext"
        cmd += f" --batch_size {args.batch_size}"
        
        if not run_command(cmd, "æ•°æ®é¢„å¤„ç†"):
            print("âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return
    else:
        if not check_file_exists(args.output, "pklæ•°æ®æ–‡ä»¶"):
            print("âŒ è·³è¿‡æ•°æ®é¢„å¤„ç†ä½†pklæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ç»§ç»­")
            return
    
    # æ­¥éª¤3: æ¨¡å‹è®­ç»ƒ
    cmd = f"python train_chinese.py --data_path {args.output} --base_model {args.model}"
    cmd += f" --epochs {args.epochs} --batch_size {args.batch_size}"
    cmd += f" --output_dir {args.output_dir}"
    
    if args.use_graph:
        cmd += " --graph_model --nodal_attention"
    
    if args.use_bert:
        cmd += " --use_bert"
        # BERTéœ€è¦æ›´å°çš„batch_size
        if args.batch_size > 16:
            cmd = cmd.replace(f"--batch_size {args.batch_size}", "--batch_size 16")
            print("âš ï¸ ä½¿ç”¨BERTæ—¶è‡ªåŠ¨è°ƒæ•´batch_sizeä¸º16")
    
    if not run_command(cmd, "æ¨¡å‹è®­ç»ƒ"):
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return
    
    # å®Œæˆ
    print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print("="*60)
    print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {args.output_dir}")
    print(f"æœ€ä½³æ¨¡å‹æ–‡ä»¶: best_model_*.pkl")
    print(f"è®­ç»ƒå†å²: training_history.json")
    print("="*60)
    
    # æ˜¾ç¤ºç»“æœæ–‡ä»¶
    if os.path.exists(args.output_dir):
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        for file in os.listdir(args.output_dir):
            file_path = os.path.join(args.output_dir, file)
            if os.path.isfile(file_path):
                size = os.path.getsize(file_path)
                print(f"  {file} ({size/1024/1024:.2f} MB)")

if __name__ == '__main__':
    main()
