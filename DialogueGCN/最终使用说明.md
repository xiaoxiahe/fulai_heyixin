## 项目总览

本项目提供中文多轮对话情绪识别的完整流程：数据→训练→单模型评估→多模型集成→最终混合系统。核心脚本集中在 `DialogueGCN/` 目录及仓库根目录。

- **单模型评估**: `DialogueGCN/evaluate_trained_model.py`
- **多模型集成评估**: `DialogueGCN/evaluate_ensemble_models.py`
- **快速评估启动器**: `DialogueGCN/quick_evaluate.py`
- **最终混合情绪系统**: `DialogueGCN/final_emotion_system.py`
- **中文训练入口**: `DialogueGCN/train/run_chinese_training.py`

---

## 环境准备

- 操作系统: Windows 10/11 或 Linux/MacOS
- Python: 3.8+
- GPU（可选但推荐）: CUDA 11+ 与对应的 PyTorch 版本

安装依赖（示例）:

```bash
pip install -r datapre/requirements.txt
pip install -r emotion_evaluate/requirements.txt
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers scikit-learn pandas numpy tqdm pymysql
```

首次运行会自动下载 `hfl/chinese-roberta-wwm-ext` 至 `DialogueGCN/train/bert_cache/`（或当前目录下 `./bert_cache`）。

---

## 数据准备

- 训练/评估依赖 `datapre/` 输出的 pkl 或测试表格：
  - 训练集特征: `datapre/features_full.pkl` 或自定义 pkl
  - 评估数据（表格）: 包含列 `dialogue_id, speaker(user|robot), utterance, emotion_label`
- 标签集（常用）:
  - 单模型/集成评估: `NEUTRAL, HAPPY, SAD, ANGRY`
  - 最终混合系统还支持: `SURPRISE`（内部统一到 5 类）

---

## 训练（中文）

快速入口：

```bash
# GPU 训练（推荐）
python DialogueGCN/train/run_chinese_training.py --data_path datapre/features_full.pkl --gpu

# 自定义参数示例
python DialogueGCN/train/run_chinese_training.py \
  --data_path datapre/features_full.pkl \
  --epochs 100 \
  --batch_size 64 \
  --lr 1e-4 \
  --gpu
```

说明：
- 训练过程会在 `DialogueGCN/train/saved/` 或 `DialogueGCN/saved/` 下生成模型（.pkl 或 .pth，视脚本实现而定）。
- 维度、窗口、注意力等配置会随检查点一并保存，评估时自动匹配。

---

## 单模型评估（增强版）

脚本: `DialogueGCN/evaluate_trained_model.py`

- 交互式预测：
```bash
python DialogueGCN/evaluate_trained_model.py --model_path saved/best_model_Graph_LSTM.pkl --mode interactive --device auto
```

- 批量评估（xlsx/csv）：
```bash
python DialogueGCN/evaluate_trained_model.py \
  --model_path saved/best_model_Graph_LSTM.pkl \
  --mode file \
  --test_file improved_test_data.xlsx \
  --device auto
```

- 置信度阈值（全局或逐类）：
```bash
# 全局阈值：非 NEUTRAL 情绪置信度需 > 0.5
python DialogueGCN/evaluate_trained_model.py --model_path saved/best_model_Graph_LSTM.pkl --mode file \
  --test_file improved_test_data.xlsx --confidence_threshold 0.5

# 个性化阈值：按类设置（优先级高于全局阈值）
python DialogueGCN/evaluate_trained_model.py --model_path saved/best_model_Graph_LSTM.pkl --mode file \
  --test_file improved_test_data.xlsx --per_emotion_thresholds "HAPPY:0.47,SAD:0.44,ANGRY:0.74,NEUTRAL:0.30"
```

输出包含：总体准确率、每类 Precision/Recall/F1、混淆矩阵、耗时统计、并提供“预测成功时的置信度统计”以辅助阈值设置。

---

## 多模型集成评估

脚本: `DialogueGCN/evaluate_ensemble_models.py`

- 支持方法：
  - `vote` 投票（默认）
  - `avg_confidence` 平均置信度
  - `weighted_avg` 加权平均（以各自置信度为权重）

示例：

```bash
# 交互式集成评估（投票）
python DialogueGCN/evaluate_ensemble_models.py \
  --model_paths pkl/best_model_Graph_LSTM.pkl pkl/best_model_Graph_LSTM_2.pkl \
  --mode interactive \
  --ensemble_method vote

# 文件评估（平均置信度）
python DialogueGCN/evaluate_ensemble_models.py \
  --model_paths pkl/best_model_Graph_LSTM.pkl pkl/best_model_Graph_LSTM_2.pkl \
  --mode file \
  --test_file improved_test_data.xlsx \
  --ensemble_method avg_confidence
```

建议：
- 模型来源尽量多样（不同种子/超参/数据切分），可提升集成收益。
- 3–5 个模型常见即有显著提升；7 个以上收益递减且推理变慢。

---

## 快速评估启动器

脚本: `DialogueGCN/quick_evaluate.py`

功能：自动搜索模型并引导交互/文件评估，支持全局/逐类阈值模式。

运行：
```bash
python DialogueGCN/quick_evaluate.py
```
按提示选择模式与阈值策略，脚本会拼装并执行增强评估命令。

---

## 最终混合情绪系统

脚本: `DialogueGCN/final_emotion_system.py`

目标：结合 DialogueGCN 与大模型（可选）实现更稳健的在线推断策略：
- 首轮默认走大模型（可选，内置兜底策略）
- 后续以 DialogueGCN 为主，并根据历史分布上升、neutral 接近度、置信度变化等条件触发大模型复核或融合
- 支持将轮次结果持久化至 MySQL（可选）

使用方式（交互 Demo）：
```bash
python DialogueGCN/final_emotion_system.py
```
常用命令：`quit` 退出，`clear/reset` 清空上下文，`history` 查看历史，`test/test_lm/test_dgcn/interactive_dgcn` 运行内置测试。

注意：
- 若未配置大模型 SDK，将使用内置模拟逻辑，流程不受阻。
- MySQL 持久化需设置 `MYSQL_HOST, MYSQL_PORT, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB` 环境变量，并安装 `pymysql`。

---

## 性能与资源建议

- GPU 推理可复用同一 BERT 实例，显著节省显存，提高吞吐
- BERT 池化策略已在评估脚本内自适配（768 与 2304 维），避免维度不一致
- 控制上下文长度（如 5–10 轮）以平衡时延与上下文信息量

---

## 常见问题（FAQ）

- 模型文件找不到？
  - 确认路径；或放置到 `DialogueGCN/saved/`、`saved/` 或项目根目录
- 维度/形状不匹配？
  - 评估脚本会从检查点推断维度并自适配；仍失败请确认训练与推理 BERT 特征配置一致
- 集成反而变差？
  - 移除明显性能较差或高度相似的模型；尝试 `weighted_avg`
- BERT 下载慢或失败？
  - 预先将 `hfl/chinese-roberta-wwm-ext` 放到 `./bert_cache` 或 `DialogueGCN/train/bert_cache`

---

## 目录参考

```text
DialogueGCN/
├─ evaluate_trained_model.py        # 单模型评估（增强版）
├─ evaluate_ensemble_models.py      # 多模型集成评估
├─ quick_evaluate.py                # 快速评估启动器
├─ final_emotion_system.py          # 最终混合系统（GCN+大模型）
└─ train/
   ├─ run_chinese_training.py       # 中文训练入口
   └─ bert_cache/                   # 预训练模型缓存（自动）
```

---

## 最小可运行示例

```bash
# 1) 使用已有最优模型做交互式评估
python DialogueGCN/evaluate_trained_model.py --model_path pkl/best_model_Graph_LSTM.pkl --mode interactive

# 2) 使用两个模型做投票集成（交互式）
python DialogueGCN/evaluate_ensemble_models.py \
  --model_paths pkl/best_model_Graph_LSTM.pkl pkl/best_model_Graph_LSTM_2.pkl \
  --mode interactive --ensemble_method vote

# 3) 运行最终混合系统 Demo
python DialogueGCN/final_emotion_system.py
```

---

## 版本与支持

- 若遇问题，请优先确认：模型路径、依赖安装、BERT 缓存、评估数据列字段是否齐全
- 需要进一步帮助，可附完整命令、报错与环境信息（OS、Python、CUDA、GPU 型号）
